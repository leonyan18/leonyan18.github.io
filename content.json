{"posts":[{"title":"牛客模拟缓存","text":"BM100 设计LRU缓存结构题意链接：设计LRU缓存结构_牛客题霸_牛客网 (nowcoder.com) 思路linkedHashMap可以维护元素插入顺序或者元素访问顺序，那么第一个元素即为最远没有访问过的， set和get在通常情况是O(1),最坏情况是O(logn) 使用LinkedHashMap设置为访问次序 set的时候要注意容量，移除最久未使用的key 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.yan.simulation;import com.yan.base.Solution;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.io.InputStream;import java.io.OutputStream;import java.util.LinkedHashMap;//@Servicepublic class LRUCacheSolution implements Solution { private LinkedHashMap&lt;Integer,Integer&gt; map; private int capacity; @Override public void solve(InputStream in, OutputStream outputStream) { System.out.println(&quot;test&quot;); LRUCacheSolution lruCacheSolution=new LRUCacheSolution(2); lruCacheSolution.set(1,1); lruCacheSolution.set(2,2); System.out.println(lruCacheSolution.get(1)); lruCacheSolution.set(3,3); System.out.println(lruCacheSolution.get(2)); lruCacheSolution.set(4,4); System.out.println(lruCacheSolution.get(1)); System.out.println(lruCacheSolution.get(3)); System.out.println(lruCacheSolution.get(4)); } public LRUCacheSolution() { } public LRUCacheSolution(int capacity) { this.capacity=capacity; // 设置为访问顺序 map= new LinkedHashMap&lt;&gt;(capacity,0.75f,true); // write code here } public int get(int key) { if (!map.containsKey(key)){ return -1; } int val=map.get(key); return val; } public void set(int key, int value) { // 只有大小等于容量并且插入的时候key不存在的时候才进行删除之前的 if(map.size()==capacity&amp;&amp;!map.containsKey(key)){ // 删除最远没用过的 int temp= map.entrySet().iterator().next().getKey(); map.remove(temp); } map.put(key,value); }} BM101 设计LFU缓存结构题意 思路个人思路（非最佳）使用优先队列，记录查找和查询次数以及相对位置，按照次数最少排序，使用懒删除的思想在容量满的时候才对前面的元素去除脏数据 使用数据结构 12345678910 private HashMap&lt;Integer, Integer&gt; map;// key -value private HashMap&lt;Integer, Integer&gt; countMap;// key -次数 private HashMap&lt;Integer, Integer&gt; opMap;// key -操作数 private int capacity; // 容量 private int op;// 操作数class Node { int key; int cnt; int pos; } 插入时： 容量为满的的时候，会先查询队首元素是否为正确节点步骤如下 判断这个节点是否正确的操作数 判断这个节点是否已删除 不正确的话就弹出节点，并重复操作，直至正确。countMap和map中回删除这个key； 插入和获取节点，countMap，map和queue更新数据，同时op操作数++ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140package com.yan.simulation;import com.yan.base.Solution;import org.springframework.stereotype.Service;import java.io.InputStream;import java.io.OutputStream;import java.util.*;@Servicepublic class LFUCacheSolution implements Solution { private HashMap&lt;Integer, Integer&gt; map; private HashMap&lt;Integer, Integer&gt; countMap; private HashMap&lt;Integer, Integer&gt; opMap; private int capacity; private int op; private PriorityQueue&lt;Node&gt; queue; @Override public void solve(InputStream in, OutputStream outputStream) { LFUCacheSolution lfuCacheSolution = new LFUCacheSolution(3); lfuCacheSolution.set(2054879058, -121373736); lfuCacheSolution.set(2054879053, -121373736); lfuCacheSolution.set(2054879025, -121373736); lfuCacheSolution.set(2, 4); lfuCacheSolution.set(3, 5); System.out.println(lfuCacheSolution.get(2)); lfuCacheSolution.set(4, 4); System.out.println(lfuCacheSolution.get(1)); } public int[] LFU(int[][] operators, int k) { ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; operators.length; i++) { if (operators[i][0] == 1) { set(operators[i][1], operators[i][2]); } else { int temp = get(operators[i][1]); arrayList.add(temp); } } int[] d = new int[arrayList.size()]; for (int i = 0; i &lt; arrayList.size(); i++) { d[i] = arrayList.get(i); } return d; } public LFUCacheSolution() { } public LFUCacheSolution(int capacity) { this.capacity = capacity; map = new HashMap&lt;&gt;(capacity); countMap = new HashMap&lt;&gt;(capacity); opMap = new HashMap&lt;&gt;(capacity); queue = new PriorityQueue&lt;&gt;(capacity * 4, new Comparator&lt;Node&gt;() { @Override public int compare(Node o1, Node o2) { if (o1.cnt != o2.cnt) { return o1.cnt - o2.cnt; } else { return o1.pos - o2.pos; } } }); } public int get(int key) { if (!map.containsKey(key)) { return -1; } int val = map.get(key); int cnt = countMap.get(key); countMap.put(key, cnt + 1); opMap.put(key, op); queue.add(new Node(key, cnt + 1, op)); op++; return val; } public void set(int key, int value) { // 只有大小等于容量并且插入的时候key不存在的时候才进行删除之前的 if (map.size() == capacity &amp;&amp; !map.containsKey(key)) { // 删除最远没用过的 Node temp = queue.peek(); while (!map.containsKey(temp.key) || (temp.pos != opMap.get(temp.key))) { queue.poll(); temp = queue.peek(); } temp=queue.poll(); map.remove(temp.key); countMap.remove(temp.key); } map.put(key, value); countMap.put(key, 1); opMap.put(key, op); queue.add(new Node(key, 1, op)); op++; } class Node { int key; int cnt; int pos; public Node() { } public Node(int key, int cnt, int pos) { this.key = key; this.cnt = cnt; this.pos = pos; } @Override public boolean equals(Object o) { if (this == o) return true; if (!(o instanceof Node)) return false; Node node = (Node) o; if (key != node.key) return false; if (cnt != node.cnt) return false; return pos == node.pos; } @Override public int hashCode() { int result = key; result = 31 * result + cnt; result = 31 * result + pos; return result; } }} 题解思路题解 | #设计LFU缓存结构#_牛客博客 (nowcoder.net) 需要在O(1)时间内实现两个操作，我们第一时间想到的还是哈希表，利用哈希表保存LFU的key值，而哈希表的value值对应了另一边存着每个缓存需要的类的节点，这样就实现了直接访问。 但是我们还需要每次最快找到最久未使用的频率最小的节点，这时候我们可以考虑使用一个全局变量，跟踪记录最小的频率，有了最小的频率（当你使用set方法的时候每次进来的都是最小频率的，所以需要更新的时候通常更新为1，或者频率为最小频率的没有了进行++操作），怎样直接找到这个频率最小的节点，还是使用哈希表，key值记录各个频率，而value值就是后面接了一串相同频率的节点。如何保证每次都是最小频率的最久为使用，我们用双向链表将统一频率的节点连起来就好了，每次新加入这个频率的都在链表头，而需要去掉的都在链表尾。 算法全部代码参考leonyan18/AlgorithmCodeInJava (github.com)","link":"/2022/12/26/NowcoderEmulateCache/"},{"title":"Hexo博客搭建以及文件同步","text":"总体结构 Hexo+ Icarus主题作为博客基础，在此基础对此主题进行布局修改 修改和发布文章，一开始是采用了hexo-admin的方式进行修改的，后面感觉还是麻烦和本地typora差距甚大，于是使用了Alist和RaiDrive进行本地挂载远程目录的方式，并结合图床。 博客搭建hexo文档 | Hexo 安装 Hexo 需要先安装下列应用程序即可： Node.js (Node.js 版本需不低于 10.13，建议使用 Node.js 12.0 及以上版本) Git 1234#全局安装npm install -g hexo-cli#局部安装npm install hexo hexo主题Icarusgithub地址ppoffice/hexo-theme-icarus: A simple, delicate, and modern theme for the static site generator Hexo. (github.com) 文档地址Icarus快速上手 - Icarus (ppoffice.github.io) 不过个人推荐可以安装之前的库如4.4版本的，5.0以上版本布局都不在themes/Icarus/layout/下了,都在node_modules里了，后面修改原来的布局就十分麻烦 12npm install hexo-theme-icarushexo config theme icarus 配置文件可以参考自动生成的_config.icarus.yml.example，以及对应的文档Tag: Icarus用户指南 - Icarus (ppoffice.github.io) 布局问题参考链接Hexo主题Icarus的自定义 - Astroblog (astrobear.top) 由于原来看文章的时候多栏布局导致文章内容过于窄了所以第一步需要先改成双栏 还需要新建一个文章的单独布局_config.post.yml代码如下，即所有widget都在左或者右边 12345678910111213141516171819202122sidebar: left: sticky: true right: sticky: falsewidgets: - position: left type: profile author: 颜晨曦 author_title: 研究生 location: 浙江 台州 avatar: /img/avatar.png avatar_rounded: false gravatar: follow_link: https://github.com/leonyan18 - position: left type: toc index: true collapsed: true depth: 6 还有一个问题就是文章内容宽度还是偏窄，之前版本的修改方法现在都要里面的文件对应到node_modules/hexo-theme-Icarus中文件进行修改，然后重新设置主题，并重启。 之前方法参考链接Hexo主题Icarus的自定义 - Astroblog (astrobear.top)，将 Icarus5的优雅替代方法主要还是强迫症，怕以后备份的时候忘记node_modules里的东西，要重新修改布局一遍 将node_modules/hexo-theme-Icarus中的文件复制到最外层主题themes/icarus/中（没有就创建），那么其实你就相当于创建了一个和Icarus一模一样的主题，和之前Icarus4的做法一样，直接在这里面改动就行。 文件同步参考一下之前的文章Alist+RaiDrive+阿里云盘=本地网盘+文件实时同步+备份 - blog (dawnchannel.tech) 使用Alist添加本地存储(博客目录/source/_posts/) RaiDrive就会映射到本地盘中 博客编写安装typoraTypora — a markdown editor, markdown reader. 使用picGo作为图床，添加你有的图床，我是用的minio图床，需要在里面下载一个插件即可 然后在Typora中进行配置，配置完成之后你的复制的图片点击上传就能上传到图床之上","link":"/2022/12/27/blog/"},{"title":"Alist+RaiDrive+阿里云盘&#x3D;本地网盘+文件实时同步+备份","text":"总体结构 远程存储空间为服务器上指定目录和阿里云盘指定目录 Alist作为文件管理工具，并向RaiDrive 提供 webDAV接口 Rai作为本地挂载远程工具的软件，使原本需要读取远程文件的操作像本地操作一样简单 Alist安装以及使用先看官方文档一键脚本 | AList文档 (nn.ci) 本人使用官方推荐的这个脚本安装 123456#安装curl -fsSL &quot;https://alist.nn.ci/v3.sh&quot; | bash -s install#更新curl -fsSL &quot;https://alist.nn.ci/v3.sh&quot; | bash -s update#卸载curl -fsSL &quot;https://alist.nn.ci/v3.sh&quot; | bash -s uninstall 一键脚本安装之后，默认安装在/opt/alist 后续获得管理员密码要从手动安装的运行里面找，这个一开始我也没找到 123456# 进入文件夹cd /opt/alist# 运行程序./alist server# 获得管理员信息./alist admin 管理员登录 然后就是在web页面上操作了，默认是5244端口，服务器的话需要安全组开端口 之后看文档解决一下通用项 | AList文档 (nn.ci) 添加服务器本地存储本地存储 | AList文档 (nn.ci)，可以日后作为服务器和本地实时同步文件，带宽不高就要用来看视频了 添加阿里云盘阿里云盘 | AList文档 (nn.ci)，可以它用他看视频听歌，切记切记WebDAV 策略使用302重定向，这样用的就不是你服务器的带宽了，而是阿里云盘的 这些文档都讲的比较清晰了，就不再赘述 Rai软件安装下载链接：下载 (raidrive.com.cn) 直接点击安装就行，期间会有安装其他软件和一些设备软件，安装就行 然后点击添加，选择NS webDAV 然后就行了","link":"/2022/12/28/local_sync/"},{"title":"使用Github Actions 动态更新Github主页","text":"总体思路借鉴思路地址使用Github Actions 动态更新Github主页 - 方圆小站 (fangyuanxiaozhan.com) 原文讲的东西不够全，我这会补充一点 项目参考地址leonyan18/leonyan18 (github.com) python脚本爬取博客更新内容，并写入更新到指定位置 github action 每天定时启动这个任务 python脚本第一步是选择你要插入的位置，并修改脚本12345678910111213这是我的ReadME.md## Recent Blog Posts(update time:2022-12-29 10:15:20)[Alist+RaiDrive+阿里云盘&amp;#x3D;本地网盘+文件实时同步+备份](http://dawnchannel.tech/2022/12/28/local_sync/)[Hexo博客搭建以及文件同步](http://dawnchannel.tech/2022/12/27/blog/)[牛客模拟缓存](http://dawnchannel.tech/2022/12/26/NowcoderEmulateCache/)&lt;br/&gt;## 💻:keyboard: Languages and Tools 我是在## Recent Blog Posts和## 💻:keyboard: Languages and Tools 之间进行插入的，根据实际情况替换值，我这边是多了几个回车，需要注意一下，在本地调试通过之后在进行上传。 在main.py对应位置进行修改，在两个insert_info = 的位置 第二步 根据实际返回修改get_link_info函数由于本人是通过hexo+icarus主题实现的，博客内容可以通过http://dawnchannel.tech/content.json直接获得，可以将其替换成自己的地址。 其他地址需要个人自定义了，还要注意一点我这个是按照时间顺序下来的，所以我还进行了一个逆序操作。 1234567891011121314151617181920212223242526272829303132333435363738394041import timeimport osimport reimport pytzimport requestsimport jsonfrom datetime import datetimedef get_link_info(feed_url, num): result = &quot;&quot; response = requests.get(feed_url).text response=json.loads(response) feed_entries = response[&quot;posts&quot;] feed_entries.reverse() feed_entries_length = len(feed_entries) all_number = 0 if(num &gt; feed_entries_length): all_number = feed_entries_length else: all_number = num for entrie in feed_entries[0: all_number]: title = entrie[&quot;title&quot;] link = &quot;http://dawnchannel.tech&quot;+entrie[&quot;link&quot;] result = result + &quot;\\n&quot; + &quot;[&quot; + title + &quot;](&quot; + link + &quot;)&quot; + &quot;\\n&quot; return resultdef main(): insert_info = get_link_info(&quot;http://dawnchannel.tech/content.json&quot;, 6) # 替换 ---start--- 到 ---end--- 之间的内容 # pytz.timezone('Asia/Shanghai')).strftime('%Y年%m月%d日%H时M分') fmt = '%Y-%m-%d %H:%M:%S %Z%z' insert_info = &quot;## Recent Blog Posts(&quot; + &quot;update time:&quot;+ datetime.fromtimestamp(int(time.time()),pytz.timezone('Asia/Shanghai')).strftime('%Y-%m-%d %H:%M:%S') +&quot;)\\n&quot; + insert_info + &quot;\\n\\n&lt;br/&gt;\\n\\n## 💻:keyboard: Languages and Tools &quot; # 获取README.md内容 print(insert_info) with open (os.path.join(os.getcwd(), &quot;README.md&quot;), 'r', encoding='utf-8') as f: readme_md_content = f.read() new_readme_md_content = re.sub(r'## Recent Blog Posts(.|\\n)*## 💻:keyboard: Languages and Tools ', insert_info, readme_md_content) with open (os.path.join(os.getcwd(), &quot;README.md&quot;), 'w', encoding='utf-8') as f: f.write(new_readme_md_content)main() 第三步 本地调试主要测试一下，本地的ReadME文件是否正常，在没有最近博客的时候和有最近博客的时候都测试一下。 github actions前期准备先解释下action的流程 创建所需要的环境 安装对应依赖 git操作 然后看下我们的目录结构以及所需要的东西，缺一样都不可以 ReadMe.md ，主要需要修改的对象 main.py，python脚本用于修改内容 Pipfile，创建环境安装对应依赖 .gitignore，忽略生成的其他无关文件 .gitignore和Pipfile文件直接使用参考仓库里，如果用到其他库或者新增其他文件了，请自行添加。 启动actions点击仓库下面的actions按钮，创建对应main.yml 1234567891011121314151617181920212223242526272829303132name: 'leonyan18'on: push: schedule: - cron: '0 1 * * *'jobs: stale: runs-on: ubuntu-latest strategy: matrix: # in this example, there is a newer version already installed, 3.7.7, so the older version will be downloaded python-version: ['3.7.4'] steps: - uses: actions/checkout@v2 # Checking out the repo - name: Install dependecies uses: VaultVulp/action-pipenv@v2.0.1 with: command: install -d # Install all dependencies, including development ones - name: Build uses: VaultVulp/action-pipenv@v2.0.1 with: command: run build - name: Commit and push if changed # 更新README.md run: | git diff git config --global user.email &quot;1183503933@qq.com&quot; git config --global user.name &quot;leonyan&quot; git add README.md git commit -m &quot;Github Action Auto Updated&quot; git push 提交之后，去Enable这个job就可以每天更新了。 注意当你重新启动失败的job的时候，一定要手动触发，重新运行之前的已经不行了，因为readme已经被修改过了，可以通过重新git提交会自动触发 或者改为手动触发 123on: # 手动触发事件 workflow_dispatch:","link":"/2022/12/29/GetRecentBlog/"},{"title":"BM95 分糖果问题","text":"题意链接：分糖果问题_牛客题霸_牛客网 (nowcoder.com) 思路题意可得 极小值点只给一颗糖。 如果左边都比右边小那么是个单调递增序列，且差值为1。如果左边都比右边大就可同理得。 如果相等的话，只考虑不相等一边的情况，如果都相等则为1。 将数组拆分一段又一段的单调序列话，就剩下一个极大值点需要讨论 如果比左右两边都大，要同时满足左右两边的这点的糖果数就取决于左右两边谁需求的糖果数大了。 一开始我的思路，找单调递增和递减的长度，算一个等差数列，打算扫一遍算出来，但是后来想想好像情况有点复杂，总共有四种情况，比两边都大的点，即极大值点还要去遍历右边才能知道他的值，这样的话就是O(n^2),显然不行 优化方法就是从左往右和从左往右都扫一遍，每次只算一边的情况，然后取极大值。 具体步骤 从左边开始扫，如果左边比他大，那么糖果数=左边糖果数+1，反之为1。糖果数组记为candyL 从右边开始扫，如果右边比他大，那么糖果数=右边糖果数+1，反之为1。糖果数组记为candyR 从左边开始累加max(candyL[i],candyR[i]),最后输出 代码如下 123456789101112131415161718192021222324252627282930public int candy(int[] arr) { // write code here int ans = 0; int[] candyl=new int[arr.length+5]; int[] candyr=new int[arr.length+5]; int pre=arr[0]; candyl[0]=1; candyr[arr.length-1]=1; for (int i = 1; i &lt; arr.length; i++) { if(arr[i]&gt;pre){ candyl[i]=candyl[i-1]+1; }else { candyl[i]=1; } pre=arr[i]; } pre=arr[arr.length-1]; for (int i = arr.length-2; i &gt;= 0; i--) { if(arr[i]&gt;pre){ candyr[i]=candyr[i+1]+1; }else { candyr[i]=1; } pre=arr[i]; } for (int i=0;i&lt;arr.length;i++){ ans+=Math.max(candyl[i],candyr[i]); } return ans; } 算法全部代码参考leonyan18/AlgorithmCodeInJava (github.com)","link":"/2022/12/30/BM95/"},{"title":"数组中的逆序对","text":"数组中的逆序对_牛客题霸_牛客网 (nowcoder.com) 题意 思路尝试：每次看到这个题，我都老是想记录原来位置然后再排个序看看和原来的差值，即是答案。后面想想快速排序试试，移到前面的+上差值，移到后面的减去差值，中间过程不一定就是差值。 ​ 使用归并排序，排序过程中，逆序对会随着元素慢慢移到正确的位置而减少，而且每次减少的逆序对是可以统计的。将两个有序数组进行合并的时候，当右数组的元素移动到左数组的原来位置的时候，减少的逆序对数为移动距离，记录该值即可。 ​ 至于取余的问题每次都进行cnt=(cnt+mod)%mod就可以了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public long cnt = 0; public long mod = 1000000007; public void Merge(int[] array, int[] temp, int l, int r) { if(l&gt;=r) return; int mid=(l+r)/2; int pos=l,lpos=l,rpos=mid+1; while (lpos&lt;=mid&amp;&amp;rpos&lt;=r) { if (array[lpos]&lt;=array[rpos]){ temp[pos]=array[lpos]; lpos++; }else { temp[pos]=array[rpos]; cnt+=rpos-pos; cnt=(cnt+mod)%mod; rpos++; } pos++; } while(lpos&lt;=mid){ temp[pos]=array[lpos]; lpos++; pos++; } while(rpos&lt;=r){ temp[pos]=array[rpos]; rpos++; pos++; } for (int i = l; i &lt;= r; i++) { array[i]=temp[i]; } } public void MergeSort(int[] array, int[] temp, int l, int r) { int cnt; if (l &gt;= r) return; int mid = (l + r) / 2; MergeSort(array, temp, l, mid); MergeSort(array, temp, mid + 1, r); Merge(array,temp, l, r); } public int InversePairs(int[] array) { cnt = 0; int[] temp = new int[array.length]; MergeSort(array, temp, 0, array.length - 1); return (int) cnt; } 算法全部代码参考leonyan18/AlgorithmCodeInJava (github.com)","link":"/2023/01/01/BM20/"},{"title":"BM75 编辑距离(一)","text":"题意编辑距离(一)_牛客题霸_牛客网 (nowcoder.com) 思路主要难点是如何建立dp数组，我当时想的是（i，j）表示的是i和j的区间已经完成操作，但是递推方程需要左边和右边都有，所以不行后续的j表示长度的话也不行。忘得太快了。。。。 题解 | #编辑距离(一)#_牛客博客 (nowcoder.net) 把第一个字符串变成第二个字符串，我们需要逐个将第一个字符串的子串最少操作下变成第二个字符串，这就涉及了第一个字符串增加长度，状态转移，那可以考虑动态规划。用dp[i][j]表示从两个字符串首部各自到str1[i]和str2[j]为止的子串需要的编辑距离，那很明显dp[str1.length][str2.length]就是我们要求的编辑距离。（下标从1开始） 具体做法： step 1：初始条件： 假设第二个字符串为空，那很明显第一个字符串子串每增加一个字符，编辑距离就加1，这步操作是删除；同理，假设第一个字符串为空，那第二个字符串每增加一个字符，编辑距离就加1，这步操作是添加。 step 2：状态转移： 状态转移肯定是将dp矩阵填满，那就遍历第一个字符串的每个长度，对应第二个字符串的每个长度。如果遍历到str1[i]和 str2[j]的位置，这两个字符相同，这多出来的字符就不用操作，操作次数与两个子串的前一个相同，因此有dp[i][j]=dp[i-1][j-1]；如果这两个字符不相同，那么这两个字符需要编辑，但是此时的最短的距离不一定是修改这最后一位，也有可能是删除某个字符或者增加某个字符，因此我们选取这三种情况的最小值增加一个编辑距离，即dp[i][j]=min(dp[i-1][j-1],dp[i][j-1],dp[i][j])+1。 123456789101112131415161718192021222324public int editDistance(String str1, String str2) { // write code here int len1 = str1.length(); int len2 = str2.length(); int[][] dp = new int[len1 + 5][len2 + 5]; for (int i = 0; i &lt;= len1; i++) { dp[i][0] = i; } for (int i = 0; i &lt;= len2; i++) { dp[0][i] = i; } for (int i = 1; i &lt;= len1; i++) { for (int j = 1; j &lt;= len2; j++) { if (str1.charAt(i - 1) == str2.charAt(j - 1)) { dp[i][j] = dp[i - 1][j - 1]; } else { dp[i][j] = dp[i - 1][j - 1] + 1; dp[i][j] = Math.min(dp[i - 1][j] + 1, dp[i][j]); dp[i][j] = Math.min(dp[i][j - 1] + 1, dp[i][j]); } } } return dp[len1][len2]; } 算法全部代码参考leonyan18/AlgorithmCodeInJava (github.com)","link":"/2023/01/06/BM75/"},{"title":"Java问题收集","text":"理解原码、反码、补码、移码 符号位：0位正数，1为负数 原码不能进行运算 正数的原码和反码一样，负数的反码是在原码的基础上，符号位不变，其余取反 正数的补码和反码一样，负数的补码是在反码的基础上进行＋1操作 移码是在补码的基础上，把符号位取反 1 -1 1+（-1） 结果 原码 0000 0001 1000 0001 1000 0010 -2 反码 0000 0001 1111 1110 1111 1111 -0 补码 0000 0001 1111 1111 0000 0000 +0 移码 1000 0001 0111 1111 1000 0000 0 取值范围 整数 n=8 原码 -(2^(n-1)-1)~2^(n-1)-1 -127~127 反码 -(2^(n-1)-1)~2^(n-1)-1 -127~127 补码 -2^(n-1)~2^(n-1)-1 -128~127 StringJava 9 为何要将 String 的底层实现由 char[] 改成了 byte[] ?JEP 254： 紧凑字符串 (openjdk.org) 我们建议更改类的内部表示 从 UTF-16 数组到数组加上编码标志字段。 新类将存储编码为 ISO-8859-1/Latin-1（每个字符一个字节），或 UTF-16（每个字符两个字节） 字符） 字符串拼接用“+” 还是 StringBuilder?可以从字节码里看出 字符串对象通过“+”的字符串拼接方式，实际上是通过 StringBuilder 调用 append() 方法实现的，拼接完成之后调用 toString() 得到一个 String 对象 。 不过，在循环内使用“+”进行字符串的拼接的话，存在比较明显的缺陷：编译器不会创建单个 StringBuilder 以复用，会导致创建过多的 StringBuilder 对象。 著作权归所有 原文链接：https://javaguide.cn/java/basis/java-basic-questions-02.html Java代理反射优缺点优点 ： 可以让咱们的代码更加灵活、为各种框架提供开箱即用的功能提供了便利 缺点 ：让我们在运行时有了分析操作类的能力，这同样也增加了安全问题。比如可以无视泛型参数的安全检查（泛型参数的安全检查发生在编译时）。另外，反射的性能也要稍差点，不过，对于框架来说实际是影响不大的。 著作权归所有 原文链接：https://javaguide.cn/java/basis/reflection.html 反射为什么慢Reflection is slow for a few obvious reasons: JIT无法对其进行优化，因为他不知道你要干什么 所有的创建和invoke操作需要去搜索 Arguments need to be dressed up via boxing/unboxing, packing into arrays, Exceptions wrapped in InvocationTargetExceptions and re-thrown etc. 参数需要通过开箱/装箱打包到数组当中，异常需要通过InvocationTargetException包装异常 还需要进行特殊处理，（如判断变量和函数访问性，检查是否有无参构造函数等） performance - Java Reflection: Why is it so slow? - Stack Overflow 静态代理JDK 动态代理和 CGLIB 动态代理对比 JDK 动态代理只能代理实现了接口的类或者直接代理接口，而 CGLIB 可以代理未实现任何接口的类。 另外， CGLIB 动态代理是通过生成一个被代理类的子类来拦截被代理类的方法调用，因此不能代理声明为 final 类型的类和方法。 就二者的效率来说，大部分情况都是 JDK 动态代理更优秀，随着 JDK 版本的升级，这个优势更加明显。 著作权归所有 原文链接：https://javaguide.cn/java/basis/proxy.html 静态代理和动态代理的对比 灵活性 ：动态代理更加灵活，不需要必须实现接口，可以直接代理实现类，并且可以不需要针对每个目标类都创建一个代理类。另外，静态代理中，接口一旦新增加方法，目标对象和代理对象都要进行修改，这是非常麻烦的！ JVM 层面 ：静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。而动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。 著作权归所有 原文链接：https://javaguide.cn/java/basis/proxy.html BigDecimal浮点数之间的等值判断，基本数据类型不能用 == 来比较，包装数据类型不能用 equals 来判断，给定误差范围 我们在使用 BigDecimal 时，为了防止精度丢失，推荐使用它的BigDecimal(String val)构造方法或者 BigDecimal.valueOf(double val) 静态方法来创建对象。 大小比较使用 a.compareTo(b)， equals() 方法不仅仅会比较值的大小（value）还会比较精度（scale），而 compareTo() 方法比较的时候会忽略精度。 著作权归所有 原文链接：https://javaguide.cn/java/basis/bigdecimal.html equals和hashcodeequals==true 说明两个对象相等。 hashcode相等，说明两个对象哈希码相等，并不代表对象相等，hashcode用于确定在哈希表中的位置。 如果hashcode相等equals不相等，说明两个对象不相等。 如果equals相等，hashcode不相等，那么在hashMap中如果两个对象被分在两个不同的哈希桶中，那么hashMap就无法进行新值覆盖，Hashset就无法进行去重。 所以重写的hashcode()在equals相等的时候必须相等。","link":"/2023/02/20/JavaProblem/"},{"title":"Java集合","text":"参考https://javaguide.cn/ ArrayList构造函数 校验初始容量 如果是无参构造，那么还是赋值一个空的数组，但是插入的时候会辨别;反之则构造一个空的数组DEFAULTCAPACITY_EMPTY_ELEMENTDATA，但是下次扩容会取最小扩容量与默认初始化长度（一般为10）进行比较。 扩容过程add函数校验大小获取最少需要长度通常是插入数量+当前长度， grow函数如果不够就进行扩容，并确定扩容大小，每次扩容变成原来的1.5倍，0.5倍由无符号右移一位得到，新长度有最少需要长度与原来长度的1.5倍的最大值得到，但是不超过SOFT_MAX_ARRAY_LENGTH，该值为Int的最大值-8，是由于部分java虚拟机需要存放object header会导致堆栈溢出，Java中的对象头信息（数组长度）需要占用8个字节的空间，所以选择了个略小于最大值的值。 Arrays.copyOf(elementData, newCapacity);将元素赋值到新地方 HashMapTableSizeFor()通过-1无符号右移给定容量的前导零长度+1得到最接近的2幂次-1，同时与最大容量进行比较 12int n = -1 &gt;&gt;&gt; Integer.numberOfLeadingZeros(cap - 1);return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; 构造函数给定的默认容量为 16，负载因子为 0.75。 参数带容量或者负载因子那就需要TableSizeFor()函数确定table大小 哈希方法12345//JDK1.7h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12);return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);//JDK1.8return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); 定位方法(n - 1) &amp; hash n为哈希表长度 put 方法首先判断数组是否经过初始化，如果没有则需要进行初始化 定位数组位置，如果无节点，则直接插入,并检验容量是否达到上限 如果存在相同的key，则直接覆盖并返回，因为没有节点增加 如果该节点是树节点，则使用红黑树的方法插入 如果该节点是普通链表节点，插入节点先判断插入后（链表长度大于阈值（默认为 8）并且 HashMap 数组长度超过 64 的时候才会执行链表转红黑树的操作，否则就只是对数组扩容） resize()方法容量参数设置首先判断原来的table是否为空，为空则进行初始化，如果也没有指定loadFactor和threshold则使用默认的， 如果不为空，容量变为原来的两倍。 同时更新threshold参数，并开辟新的node数组空间 进行迁移如果table为空，直接跳过。 遍历node数组{ ​ 如果只有一个元素，则newTab[e.hash &amp; (newCap - 1)] = e; ​ 如果是红黑树，会遍历红黑树，根据e.hash &amp; oldCap的值区分不同的位置(在原来位置j，还是j+oldcap)，且当拆分开的红黑树的节点数小于6的时候会变成链表插入到node数组中 ​ 链表同理，遍历链表根据e.hash &amp; oldCap的值区分不同的位置(在原来位置j，还是j+oldcap) } ConcurrentHashMap翻了ConcurrentHashMap1.7 和1.8的源码，我总结了它们的主要区别。 - 掘金 (juejin.cn) 线程安全实现 使用volatile保证当Node中的值变化时对于其他线程是可见的 使用table数组的头结点作为synchronized的锁来保证写操作的安全 当头结点为null时，使用CAS操作来保证数据能正确的写入。 1.7 segment+hashentry +链表的形式 ConcurrnetHashMap 由很多个 Segment 组合，而每一个 Segment 是一个类似于 HashMap 的结构，所以每一个 HashMap 的内部可以进行扩容。但是 Segment 的个数一旦初始化就不能改变，默认 Segment 的个数是 16 个，你也可以认为 ConcurrentHashMap 默认支持最多 16 个线程并发 默认初始化容量16;默认负载因子 0.75f;默认并发级别16; 1.8(38条消息) ConcurrentHashMap底层详解(图解扩容)（JDK1.8）_concurrenthashmap扩容_编程芝士的博客-CSDN博客 1234static final int MOVED = -1; // hash for forwarding nodesstatic final int TREEBIN = -2; // hash for roots of treesstatic final int RESERVED = -3; // hash for transient reservationsstatic final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash 变量sizeCtl -1 说明正在初始化，如果发现正在初始化Thread.yield(); -N 说明有N-1个线程正在进行扩容 0 表示 table 初始化大小，如果 table 没有初始化 &gt;0 表示 table 扩容的阈值，如果 table 已经初始化。 初始化表1234567891011121314151617181920212223242526private final Node&lt;K,V&gt;[] initTable() { Node&lt;K,V&gt;[] tab; int sc; // 类似CAS方法 循环初始化表 while ((tab = table) == null || tab.length == 0) { if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin // CAS else if (U.compareAndSetInt(this, SIZECTL, sc, -1)) { try { // 检查表是否初始化 if ((tab = table) == null || tab.length == 0) { int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; // 0.75 sc = n - (n &gt;&gt;&gt; 2); } } finally { sizeCtl = sc; } break; } } return tab;} put()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) { Node&lt;K,V&gt; f; int n, i, fh; K fk; V fv; if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) { if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value))) break; // no lock when adding to empty bin } else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else if (onlyIfAbsent // check first node without acquiring lock &amp;&amp; fh == hash &amp;&amp; ((fk = f.key) == key || (fk != null &amp;&amp; key.equals(fk))) &amp;&amp; (fv = f.val) != null) return fv; else { V oldVal = null; synchronized (f) { if (tabAt(tab, i) == f) { if (fh &gt;= 0) { binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) { K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) { pred.next = new Node&lt;K,V&gt;(hash, key, value); break; } } } else if (f instanceof TreeBin) { Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } else if (f instanceof ReservationNode) throw new IllegalStateException(&quot;Recursive update&quot;); } } if (binCount != 0) { if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } addCount(1L, binCount); return null;} 根据 key 计算出 hashcode，key和value均不能为null 。 判断是否需要进行初始化 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。 如果当前位置的 hashcode == MOVED == -1,则帮助扩容。 如果都不满足，则利用 synchronized 锁住这个桶,找到对应key替换值，或者插入到末尾 如果数量大于 TREEIFY_THRESHOLD 则要执行树化方法，在 treeifyBin 中会首先判断当前数组长度≥64时才会将链表转换为红黑树，与链表不同的是这个时候哈希桶里面存放的是TreeBin类，该类中有各种红黑树的方法 get()12345678910111213141516171819public V get(Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) { if ((eh = e.hash) == h) { if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; } else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) { if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; } } return null;} 根据 hash 值计算位置。 查找到指定位置，如果头节点就是要找的，直接返回它的 value. 如果头节点 hash 值小于 0 ，说明正在扩容或者是红黑树，查找之。 123static final int MOVED = -1; // hash for forwarding nodesstatic final int TREEBIN = -2; // hash for roots of treesstatic final int RESERVED = -3; // hash for transient reservations 如果是链表，遍历查找之。 addCount()1234567891011121314151617181920212223242526272829303132333435private final void addCount(long x, int check) { CounterCell[] cs; long b, s; if ((cs = counterCells) != null || !U.compareAndSetLong(this, BASECOUNT, b = baseCount, s = b + x)) { CounterCell c; long v; int m; boolean uncontended = true; if (cs == null || (m = cs.length - 1) &lt; 0 || (c = cs[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSetLong(c, CELLVALUE, v = c.value, v + x))) { fullAddCount(x, uncontended); return; } if (check &lt;= 1) return; s = sumCount(); } if (check &gt;= 0) { Node&lt;K,V&gt;[] tab, nt; int n, sc; while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) { int rs = resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT; if (sc &lt; 0) { if (sc == rs + MAX_RESIZERS || sc == rs + 1 || (nt = nextTable) == null || transferIndex &lt;= 0) break; if (U.compareAndSetInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); } else if (U.compareAndSetInt(this, SIZECTL, sc, rs + 2)) transfer(tab, null); s = sumCount(); } }} 使用了countercell数组的方法来计数，单个成员变量进行修改的时候冲突较大，所以采用分片的方法进行计数，方法类似于LongAdder计数 如果countercells数组为空，那么直接cas设置baseCount变量，失败了才进入if里面，初始化counterCells，使用fullCount初始化和重新计数counterCells，使用sumCount方法遍历counterCells 获取最后容量 如果check大于0，如果检查添加的元素量是否需要进行扩容。如果当前需要扩容，先判断是否有其他线程正在扩容有就更新sizeCTL+1（线程数+1），如果没有就更新sizeCTl rs+2（如果没有因为-1为初始化）重新计数，并且也要小于最大扩容线程数 Transfer()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) { int n = tab.length, stride; if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range if (nextTab == null) { // initiating try { @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; } catch (Throwable ex) { // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; } nextTable = nextTab; transferIndex = n; } int nextn = nextTab.length; ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab for (int i = 0, bound = 0;;) { Node&lt;K,V&gt; f; int fh; while (advance) { int nextIndex, nextBound; if (--i &gt;= bound || finishing) advance = false; else if ((nextIndex = transferIndex) &lt;= 0) { i = -1; advance = false; } else if (U.compareAndSetInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) { bound = nextBound; i = nextIndex - 1; advance = false; } } if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) { int sc; if (finishing) { nextTable = null; table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; } if (U.compareAndSetInt(this, SIZECTL, sc = sizeCtl, sc - 1)) { if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit } } else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); else if ((fh = f.hash) == MOVED) advance = true; // already processed else { synchronized (f) { if (tabAt(tab, i) == f) { Node&lt;K,V&gt; ln, hn; if (fh &gt;= 0) { int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) { int b = p.hash &amp; n; if (b != runBit) { runBit = b; lastRun = p; } } if (runBit == 0) { ln = lastRun; hn = null; } else { hn = lastRun; ln = null; } for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) { int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); } setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; } else if (f instanceof TreeBin) { TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) { int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) { if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; } else { if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; } } ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; } else if (f instanceof ReservationNode) throw new IllegalStateException(&quot;Recursive update&quot;); } } } }} 首先先划分每个线程的步长 为(n &gt;&gt;&gt; 3) / NCPU，如果只有一个cpu那么步长为整个表，同时还会在校验一次步长，小于16则设置为16 如果nextTab为空则，对数组进行扩容，申请原有数量两倍的数组，如果oom了则sizeCtl设为int最大值 然后就开始划分数组，如果node数组位置为空则直接设置fwd节点表示已经完成，moved标志表示该位置已经完成迁移无需操作，否则才会进入到链表和红黑树的迁移过程，类似于HashMap就不在赘述，最后一步同样也会设置fwd节点表示已经完成 完成特定步长后，sizeCtl-1设置结束标志退出，当最后一个线程完成后，他还会对全部数组进行个遍历确认是否有遗漏。","link":"/2023/03/30/JavaCollection/"},{"title":"java 并发","text":"参考链接：https://javaguide.cn/java/concurrent/java-concurrent-questions-02.html 参考书籍：深入理解java虚拟机第三版 Java 对象头 Mark Word 指向类的指针 数组长度（只有数组对象才有） 32位大小均为4个字节 java对象采取8字节对齐 高端面试必备：一个Java对象占用多大内存 - rickiyang - 博客园 (cnblogs.com) synchronized主要解决的是多个线程之间访问资源的同步性，可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。 历程在 Java 早期版本中，synchronized 属于 重量级锁，效率低下。这是因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高。 在 Java 6 之后， synchronized 引入了大量的优化如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。 使用方法synchronized 关键字加到 static 静态方法和 synchronized(class) 代码块上都是是给 Class 类上锁； synchronized 关键字加到实例方法上是给对象实例上锁； 尽量不要使用 synchronized(String a) 因为 JVM 中，字符串常量池具有缓存功能。 synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 synchronized 修饰的方法是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。如果是实例方法，JVM 会尝试获取实例对象的锁。如果是静态方法，JVM 会尝试获取当前 class 的锁。 锁分类级别从低到高依次是： 无锁状态 偏向锁状态 轻量级锁状态 重量级锁状态 锁可以升级，但不能降级。即：无锁 -&gt; 偏向锁 -&gt; 轻量级锁 -&gt; 重量级锁是单向的。 锁的升级参考 深入理解java虚拟机琐优化部分 自旋锁与自适应自旋在JDK 6中对自旋锁的优化，引入了自适应的自旋。自适应意味着自旋的时间不再是固定的了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定的。 如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而允许自旋等待持续相对更长的时间，比如持续100次忙循环。另一方面，如果对于某个锁，自旋很少成功获得过锁，那在以后要获取这个锁时将有可能直接省略掉自旋过程，以避免浪费处理器资源。 锁消除逃逸分析（Escape Analysis）简单来讲就是，Java Hotspot 虚拟机可以分析新创建对象的使用范围，并决定是否在 Java 堆上分配内存的一项技术。 当编译器确定一个对象没有发生逃逸时，它便会移除该对象的同步锁。 函数里多个同步方法，且所有引用没法逃逸出函数的使用范围，就可以去除同步方法。 额外标量替换 首先要明白标量和聚合量，基础类型和对象的引用可以理解为标量，它们不能被进一步分解。而能被进一步分解的量就是聚合量，比如：对象。 对象是聚合量，它又可以被进一步分解成标量，将其成员变量分解为分散的变量，这就叫做标量替换。 这样，如果一个对象没有发生逃逸，那压根就不用创建它，只会在栈或者寄存器上创建它用到的成员标量，节省了内存空间，也提升了应用程序性能。 标量替换在 JDK1.8 中也是默认开启的，但是同样也要建立在已开启逃逸分析的基础之上。 栈内存分配 栈内存分配很好理解，在上文中提过，就是将原本分配在堆内存上的对象转而分配在栈内存上，这样就可以减少堆内存的占用，从而减少 GC 的频次。 锁粗化如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部 轻量级锁加锁过程，会先在栈帧开辟一个锁记录的空间，记录原来markword中的值， 虚拟机将使用CAS操作尝试把对象的Mark Word更新为指向Lock Record的指针 解锁过程也同样是通过CAS操作来进行的，如果对象的Mark Word仍然指向线程的锁记录，那就用CAS操作把对象当前的Mark Word和线程中复制的Displaced Mark Word替换回来。假如能够成功替换，那整个同步过程就顺利完成了；如果替换失败，则说明有其他线程尝试过获取该锁，就要在释放锁的同时，唤醒被挂起的线程。 偏向锁Java6及以上版本对synchronized的优化 - 蜗牛大师 - 博客园 (cnblogs.com) 当锁对象第一次被线程获取的时候，虚拟机将会把对象头中的标志位设置为“01”、把偏向模式设置为“1”，表示进入偏向模式。同时使用CAS操作把获取到这个锁的线程的ID记录在对象的Mark Word之中。如果CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作（例如加锁、解锁及对Mark Word的更新操作等）。 一旦出现另外一个线程去尝试获取这个锁的情况，偏向模式就马上宣告结束。根据锁对象目前是否处于被锁定的状态决定是否撤销偏向（偏向模式设置为“0”），撤销后标志位恢复到未锁定（标志位为“01”）或轻量级锁定（标志位为“00”）的状态，后续的同步操作就按照上面介绍的轻量级锁那样去执行。偏向锁、轻量级锁的状态转化及对象Mark Word的关系如图所示。 当一个对象已经计算过一致性哈希码后，它就再也无法进入偏向锁状态了；而当一个对象当前正处于偏向锁状态，又收到需要计算其一致性哈希码请求[1]时，它的偏向状态会被立即撤销，并且锁会膨胀为重量级锁。(这里说的计算请求应来自于对Object::hashCode()或者System::identityHashCode(Object)方法的调用，如果重写了对象的hashCode()方法，计算哈希码时并不会产生这里所说的请求) Java内存模型 这里所讲的主内存、工作内存与第2章所讲的Java内存区域中的Java堆、栈、方法区等并不是同一个层次的对内存的划分，这两者基本上是没有任何关系的。如果两者一定要勉强对应起来，那么从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分[4]，而工作内存则对应于虚拟机栈中的部分区域。 UnsafeUnsafe 是位于 sun.misc 包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升 Java 运行效率、增强 Java 语言底层资源操作能力方面起到了很大的作用 主要功能分类 内存操作 内存屏障 123456//内存屏障，禁止load操作重排序。屏障前的load操作不能被重排序到屏障后，屏障后的load操作不能被重排序到屏障前public native void loadFence();//内存屏障，禁止store操作重排序。屏障前的store操作不能被重排序到屏障后，屏障后的store操作不能被重排序到屏障前public native void storeFence();//内存屏障，禁止load、store操作重排序public native void fullFence(); 对象操作 数据操作 CAS 操作 线程调度 Class 操作 系统信息 著作权归所有 原文链接：https://javaguide.cn/java/basis/unsafe.html 为啥要使用堆外内存。通常因为： 在进程间可以共享，减少虚拟机间的复制 对垃圾回收停顿的改善：如果应用某些长期存活并大量存在的对象，经常会出发YGC或者FullGC，可以考虑把这些对象放到堆外。过大的堆会影响Java应用的性能。如果使用堆外内存的话，堆外内存是直接受操作系统管理( 而不是虚拟机 )。这样做的结果就是能保持一个较小的堆内内存，以减少垃圾收集对应用的影响。 在某些场景下可以提升程序I/O操纵的性能。少去了将数据从堆内内存拷贝到堆外内存的步骤。 进程和线程Java 线程状态变迁图 线程初始状态：NEW 线程运行状态：RUNNABLE 线程阻塞状态：BLOCKED 线程等待状态：WAITING 超时等待状态：TIMED_WAITING 线程终止状态：TERMINATED volatile 关键字每次都要强制从主存中重新读取，如同直接在主内存中读写访问 123456789101112131415161718192021public class Singleton { private volatile static Singleton uniqueInstance; private Singleton() { } public static Singleton getUniqueInstance() { //先判断对象是否已经实例过，没有实例化过才进入加锁代码 if (uniqueInstance == null) { //类对象加锁 synchronized (Singleton.class) { if (uniqueInstance == null) { uniqueInstance = new Singleton(); } } } return uniqueInstance; }} uniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance = new Singleton(); 这段代码其实是分为三步执行： 为 uniqueInstance 分配内存空间 初始化 uniqueInstance 将 uniqueInstance 指向分配的内存地址 但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1-&gt;3-&gt;2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。 具体实现·lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。 ·unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 ·read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。 ·load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。 ·use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。 ·assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 ·store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。 ·write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中 后面最新的JSR-133文档中，已经放弃了采用这8种操作去定义Java内存模型的访问协议，缩减为4种read、write、lock和unlock 如果要把一个变量从主内存拷贝到工作内存，那就要按顺序执行read和load操作，如果要把变量从工作内存同步回主内存，就要按顺序执行store和write操作。注意，Java内存模型只要求上述两个操作必须按顺序执行，但不要求是连续执行，中间可以插入其他操作。 volatile 作用是在 use之前必须是load、load之前必须use 保证了每次使用都是最新值，assign和store也一样，保证了每次赋值都会写回到主内存 ReentrantLockReentrantLock 实现了 Lock 接口，是一个可重入且独占式的锁，和 synchronized 关键字类似。不过，ReentrantLock 更灵活、更强大，增加了轮询、超时、中断、公平锁和非公平锁等高级功能。 ThreadLocalThreadLocal 有什么用？每一个线程都有自己的专属本地变量，避免了线程安全问题。 ThreadLocal 原理ThreadLocal 可以理解为只是ThreadLocalMap的封装，传递了变量值。其实可以看成一个map，ThreadLocalMap的 key 就是 ThreadLocal对象，value 就是 ThreadLocal 对象调用set方法设置的值。 ThreadLocal 内存泄露问题是怎么导致的？ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用，而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。 这样一来，ThreadLocalMap 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap 实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后最好手动调用remove()方法 线程池为什么不使用内置线程主要还是队列长度没限制 **FixedThreadPool 和 SingleThreadExecutor**：使用的是无界的 LinkedBlockingQueue，任务队列最大长度为 Integer.MAX_VALUE,可能堆积大量的请求，从而导致 OOM。 **CachedThreadPool**：使用的是同步队列 SynchronousQueue, 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM。 ScheduledThreadPool 和 SingleThreadScheduledExecutor : 使用的无界的延迟阻塞队列DelayedWorkQueue，任务队列最大长度为 Integer.MAX_VALUE,可能堆积大量的请求，从而导致 OOM。 阻塞队列 LinkedBlockingQueue（无界队列）：由于队列永远不会被放满，因此FixedThreadPool最多只能创建核心线程数的线程。 SynchronousQueue（同步队列）： 没有容量，不存储元素，目的是保证对于提交的任务，如果有空闲线程，则使用空闲线程来处理；否则新建一个线程来处理任务 DelayedWorkQueue（延迟阻塞队列）：DelayedWorkQueue 的内部元素并不是按照放入的时间排序，而是会按照延迟的时间长短对任务进行排序，内部采用的是“堆”的数据结构，可以保证每次出队的任务都是当前队列中执行时间最靠前的。DelayedWorkQueue 添加元素满了之后会自动扩容原来容量的 1/2，即永远不会阻塞，最大扩容可达 Integer.MAX_VALUE，所以最多只能创建核心线程数的线程。","link":"/2023/04/18/javaConcurrent/"},{"title":"计算机网络","text":"https://xiaolincoding.com/network/3_tcp/tcp_interview.html TCP三次握手 三次握手才可以阻止重复历史连接的初始化（主要原因）主要是因为在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费。 三次握手才可以同步双方的初始序列号，两次握手无法知道对方是否收到自己的初始序列号 三次握手才可以避免资源浪费，两次握手服务端每次接受到syn报文就会建立一个连接 四次挥手 TCP与UDP TCP UDP 是否面向连接 是 否 是否可靠 是 否 是否有状态 是 否 传输效率 较慢 较快 传输形式 字节流 数据报文段 首部开销 20 ～ 60 bytes 8 bytes 是否提供广播或多播服务 否 是 QUIC连接1-RTT模式 0-RTT模式 对比 保持连接id 多路复用 拥塞控制","link":"/2023/05/27/network/"},{"title":"数据库","text":"数据库范式第一范式确保每列保持原子性 第二范式确保表中的每列都和主键相关 第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。 Mysql行记录存储事务事务特性ACID 原子性是通过undolog实现的 持久性是通过redolog实现的 隔离性是通过MVCC和锁实现 一致性是通过 原子性 隔离性 持久性 事务的隔离级别 序列化(SERIALIZABLE) 最高的事务隔离级别 可重复读(REPEATABLE READ) 幻读 提交读(READ COMMITTED) 不可重复读问题 读未提交(READ UNCOMMITTED) 脏读 可重复读是如何工作的可重复读是在事务开始的时候创建ReadView，并且之后所有的操作都在使用这个ReadView ReadViewReadView中有四个字段 创建时的事务id 创建时活跃但未提交事务事务id 以及其中的最大事务id和最小事务id 为什么是很大程度避免幻读Mysql存储引擎 索引 按「数据结构」分类：B+tree索引、Hash索引、Full-text索引。 按「物理存储」分类：聚簇索引（主键索引）、二级索引（辅助索引或非聚簇索引）。 按「字段特性」分类：主键索引、唯一索引、普通索引、前缀索引。 按「字段个数」分类：单列索引、联合索引。 索引失效的常见场景 对索引使用函数从 MySQL 8.0 开始，索引特性增加了函数索引，即可以针对函数计算后的值建立一个索引，也就是说该索引的值是函数计算后的值，所以就可以通过扫描索引来查询数据。 对索引隐式类型转换‘10000’ 变成 10000 过 select “10” &gt; 9 的结果来知道MySQL 的数据类型转换规则是什么： 如果规则是 MySQL 会将自动「字符串」转换成「数字」，就相当于 select 10 &gt; 9，这个就是数字比较，所以结果应该是 1； 如果规则是 MySQL 会将自动「数字」转换成「字符串」，就相当于 select “10” &gt; “9”，这个是字符串比较，字符串比较大小是逐位从高位到低位逐个比较（按ascii码） ，那么”10”字符串相当于 “1”和“0”字符的组合，所以先是拿 “1” 字符和 “9” 字符比较，因为 “1” 字符比 “9” 字符小，所以结果应该是 0。 如果在查询字段上发生自动转换那么久走不了索引 联合索引非最左匹配顺序不重要，因为有查询优化器会自动调整顺序 索引（a,b,c） b b c 不走索引 a c 截断索引 索引下推功能 WHERE 子句中的 OR在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。 explainInnoDB有哪些锁 全局锁全局锁主要应用于做全库逻辑备份，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。 例子：备份过程中购买商品后，余额已经备份过了 导致数据不一致 （如果数据库的引擎支持的事务支持可重复读的隔离级别，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。 备份数据库的工具是 mysqldump，在使用 mysqldump 时加上 –single-transaction 参数的时候，就会在备份数据库之前先开启事务。这种方法只适用于支持「可重复读隔离级别的事务」的存储引擎。） 表级锁表锁读锁和写锁 元数据锁（MDL锁） 对一张表进行 CRUD 操作时，加的是 MDL 读锁； 对一张表做结构变更操作的时候，加的是 MDL 写锁； 意向锁当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。 意向锁的目的是为了快速判断表里是否有记录被加锁。 AUTO-INC 锁AUTO-INC 锁是特殊的表锁机制，锁不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放。 InnoDB 存储引擎提供了个 innodb_autoinc_lock_mode 的系统变量，是用来控制选择用 AUTO-INC 锁，还是轻量级的锁。 当 innodb_autoinc_lock_mode = 0，就采用 AUTO-INC 锁，语句执行结束后才释放锁； 当 innodb_autoinc_lock_mode = 2，就采用轻量级锁，申请自增主键后就释放锁，并不需要等语句执行后才释放。 当 innodb_autoinc_lock_mode = 1： 普通 insert 语句，自增锁在申请之后就马上释放； 类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放； 当 innodb_autoinc_lock_mode = 2 时，并且 binlog_format = row，既能提升并发性，又不会出现数据一致性问题。 行级锁行级锁的类型主要有三类： Record Lock，记录锁，也就是仅仅把一条记录锁上； Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身； Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。 Record Lock记录锁是有 S 锁和 X 锁之分的： Gap LockGap Lock 称为间隙锁，只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象。 间隙锁虽然存在 X 型间隙锁和 S 型间隙锁，但是并没有什么区别，间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的。（无所谓只是不让在指定范围插入，多个范围也是一样不能插入，但是都可以修改） Next-Key LockNext-Key Lock 称为临键锁，是 Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。 插入意向锁在插入区间拥有间隙锁或者Next-Key Lock的时候，表明插入意向，生成插入意向锁，等待锁住区间的事务提交后即可进行插入，和间隙锁互斥","link":"/2023/06/12/database/"},{"title":"JVM","text":"Java 运行时数据区域 程序计数器当前线程所执行的字节码的行号指示器 程序计数器是唯一一个不会出现 OutOfMemoryError 的内存区域 虚拟机栈调用除本地方法外所有java方法都会产生一个栈帧，里面存放局部变量表、操作数栈、动态链接、方法返回地址 当一个方法要调用其他方法，需要将常量池中指向方法的符号引用转化为其在内存地址中的直接引用。动态链接的作用就是为了将符号引用转换为调用方法的直接引用 本地方法栈调用本地方法的栈帧，存放信息与虚拟机栈类似，方法返回地址变成出口信息 堆1.7 之前 新生代内存(Young Generation) 老生代(Old Generation) 永久代(Permanent Generation) 1.8 之后永久代变成永久代 大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 S0 或者 S1，并且对象的年龄还会加 1(Eden 区-&gt;Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。 为什么要将永久代 (PermGen) 替换为元空间 (MetaSpace) 呢? 整个永久代有一个 JVM 本身设置的固定大小上限，无法进行调整，而元空间使用的是本地内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小。你可以使用 -XX：MaxMetaspaceSize 标志设置最大元空间大小，默认值为 unlimited。能存储的信息更加多 方法区方法区会存储已被虚拟机加载的 类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存等数据。 直接内存Java NIO 中，可以直接调用Native方法分配堆外内存，DirectByteBuffer 可以直接引用这块内存 对象的创建流程 类加载检查，先去常量池中是否存在这个类的符号引用，判断是否加载、解析、初始化过，如果没有就进行类加载过程 分配内存，指针碰撞取决于内存是否规整，不规整就使用空闲列表方法 初始化零值，分配的内存进行零值填充。 加载对象头，设置gc年龄、哈希码、分代信息，指向类的指针 执行init方法. 什么是TLAB ? 从内存模型而不是垃圾收集的角度，对Eden区域继续进行划分，JVM为每个线程分配了一个私有缓存区域，它包含在Eden空间内。 多线程同时分配内存时，使用TLAB可以避免一系列的非线程安全问题，同时还能够提升内存分配的吞吐量，因此我们可以将这种内存分配方式称之为快速分配策略。 内存分配策略 对象优先在Eden区分配 大对象直接进入老年代 长期存活的对象进入老年代（没经过一次minorGC年龄就增加一岁，第一次会从Eden区进入Survivor区，岁数为1，默认十五岁进入老年代） 空间分配担保在进行minorGC之前，先确认老年代是否可以容纳所有新生代的对象，可以容纳就可以进行，否则会检查程序员是否设置参数允许担保失败 GC分类部分GC minorGC， youngGC MajorGC, OldGC MixedGC（新生代的全部和部分老年代） fullGC 死亡对象分析法引用计数法（互相引用的问题） 可达性分析（GCRoots 出发，可以是虚拟机栈和本地方法栈中的对象，方法区中静态变量或常量引用的对象，被同步锁持有的对象）宣告对象的死亡至少要经过两次标记 引用总结强引用平时使用的基本都是强引用，抛出内存不足的异常也不会报错 软引用可有可无，如果空间不够了就进行回收 弱引用一旦发现了弱引用就会进行回收 不过垃圾回收器是一个优先级很低的线程，不会很快发现这些弱引用 虚引用如果持有虚引用那么任何时候都会被回收 虚引用和软引用的区别虚引用必须和引用队列一起使用，主要目的是在虚引用被回收的时候通知一下， 官方说法是程序发现引用队列中有虚引用的时候，能在对象被回收的时候采取必要的动作 如何判断一个变量是一个废弃的变量该变量没有被任何引用 如何判断一个类是一个废弃的类 该类所有的实例都被回收 该类的classloader被回收 没有在任何地方被引用，包括反射访问其类的方法或者变量 垃圾回收垃圾收集算法标记-整理 （适合老年代这种整理情况比较少的） 标记-清除（会产生大量不连续的内存碎片） 复制（需要相同的一块内存，会导致内存减半） 分代收集（各个分代特点不同，新生代产生和消亡快，老年代比较稳定） 默认垃圾收集器JDK 默认垃圾收集器（使用 java -XX:+PrintCommandLineFlags -version 命令查看）： JDK 8：Parallel Scavenge（新生代）+ Parallel Old（老年代） JDK 9 ~ JDK20: G1 垃圾收集器新生代使用复制算法、老年代使用标记整理算法 Serial收集器单线程 在垃圾收集的时候会暂停所有其他线程、简单高效 ParNew收集器新生代使用复制算法 stw的现象仍然存在 Parallel Scavenge收集器主要关注点在吞吐量 Parallel old收集器多线程老年代收集器可以和Parallel Scavenge Serial old 收集器主要作用1.5和以前和与Parallel Scavenge、和cms收集器配合 CMS收集器以最短停顿时间为目标 初始标记（标记所有和Root连接的对象、STW） 并发标记（记录用户线程更新的引用） 重新标记（stw重新进行标记） 并发清理 cpu资源敏感，需要多个线程进行标记清理并且是与用户线程并行 无法处理浮动垃圾 基于标记-清除算法会有大量不连续内存空间产生（空间碎片） G1收集器 并行与并发：适合多cpu场景 分代收集：可以都用g1收集器，也可以分代收集 空间整合：宏观上标记-整理，微观上是基于复制算法 可预测的停顿：建立可停顿的预测时间模型， 流程 初始标记（stw） 并发标记（stw） 最终标记（stw） 筛选回收（会维护一个优先列表，根据每次允许的时间，选择回收价值最大的region） 类加载机制整体分为加载 连接 初始化 使用 卸载 加载阶段与连接阶段的部分动作(如一部分字节码文件格式验证动作)是交叉进行的，加载阶段尚未结束，连接阶段可能就已经开始了。 细分又可分为加载通过全类名获取此类的二进制数据流、将静态存储区域数据集转化为方法区运行时数据结构、内存中生成一个class对象作为访问这些数据的入口 验证检查是否符合java虚拟机规范 class文件格式检查 元数据检查（是否继承父类、是否继承了不能继承的父类） 字节码检查（通过数据流和控制流分析程序语义，对象类型转化是否合理、函数的参数类型是否正确） 符号引用检查（是否引用了其他的类、方法、字段是否存在或者拥有正确的访问权限） 准备为类变量分配内存并且设置初始化值 解析将常量池的符号引用转化为直接引用（转化为内存中偏移量） （字段、类方法、类、接口方法、方法类型、方法句柄、调用限定符） 初始化执行clinit方法 类在以下情况会主动初始化 new一个类的时候、获取或设置静态字段值的时候、调用静态方法的时候 反射 初始化类的时候父类没有初始化 main主类 MethodHandler和VarHandle 反射调用机制 default修饰的接口方法，实现该接口的类初始化了这个类也需要进行初始化 使用卸载卸载一个类3个前提 所有实例都被gc 没有在任何地方被引用 该类的所有类加载都被回收 类加载器类加载器的主要目的加载java字节码（.class文件）到jvm中（在内存中生成一个class对象） 双亲委派模型 不仅要看类名，还要看此类的类加载器是否一样 优点保证类不会被重复加载 保证java核心api稳定性（如果重写了java.lang.object的话，由于是自顶向下加载类，启动类加载器一开始就加载过了，到不了自定义的类加载器） 破坏双亲委派模型重写loadclass()方法","link":"/2023/06/14/jvm/"},{"title":"","text":"线程模型Redis 是单线程吗？Redis单线程指的是【接收客户端请求-&gt;解析请求-&gt;对数据进行读写操作-&gt;发送数据给客户端】这个过程由主线程完成的 在2.6版本会启动处理关闭文件和AOF刷盘任务 4.0版本会增加lazyFree线程释放内存，例如unlink key 、flushdb async、 flushall async 会把删除命令提交给后台线程操作，这样不会阻塞主线程，del会在主线程删除，对于大key最好还是使用unlink 这些都是耗时操作会阻塞主线程。三种任务都有各自的任务队列，会去消费这些任务 6.0之前线程模型创建socket 和epoll_create() 对象 bind()绑定端口 listen监听端口 epoll_ctl把listen socket加入到epoll，注册连接事件处理函数 调用epoll_wait() 循环： 写检查发送队列中有无发送任务，有就调用write()函数将客户端缓冲区的数据发送出去，没有发完就会注册一个写事件处理函数，等到下一个epoll_wait() 函数会继续处理 连接事件，调用连接事件处理函数主要是调用accept()函数获取连接的socket 将连接的socket加入到epoll中 注册读事件 读事件，调用读事件处理函数主要是调用read函数 读取客户端发送的数据 解析数据 执行命令 将客户端添加到发送队列 将发送给客户端的数据写到缓冲区 写事件，调用写事件处理函数主要是调用write()函数将缓冲区的数据全部发送出去，如果还没有发完会继续注册写事件处理函数，等到下一个epoll_wait() 函数会继续处理 6.0之后会对网络io请求进行多线程处理，默认只对写操作进行多线程处理 6.0之后的线程数 主线程 关闭文件线程、AOF刷盘线程、Lazzfree线程 io线程*3（默认参数是4 主线程也算进io线程当中） 数据类型Redis 提供了丰富的数据类型，常见的有五种：String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）。 随着 Redis 版本的更新，后面又支持了四种数据类型： BitMap（2.2 版新增）、HyperLogLog（2.8 版新增）、GEO（3.2 版新增）、Stream（5.0 版新增）。 StringString 类型的底层的数据结构实现主要是 int 和 SDS（简单动态字符串）。 SDS 和我们认识的 C 字符串不太一样，之所以没有使用 C 语言的字符串表示，因为 SDS 相比于 C 的原生字符串： SDS 不仅可以保存文本数据，还可以保存二进制数据。 **SDS 获取字符串长度的时间复杂度是 O(1)**。SDS 结构里用 len 属性记录了字符串长度 Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出。会自动扩容 内部编码（encoding）有 3 种 ：int、raw（字符串的长度大于 32 字节）和 embstr（字符申的长度小于等于 32 字节）。 应用分布式锁 缓存计数 共享session List如果列表的元素个数小于 512 个，列表每个元素的值都小于 64 字节，Redis 会使用压缩列表作为 List 类型的底层数据结构，反之Redis 会使用双向链表作为 List 类型的底层数据结构； 但是在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表。 应用基于 List 类型的消息队列，满足消息队列的三大需求（消息保序、处理重复的消息和保证消息可靠性）。 消息保序：使用 LPUSH + RPOP； 阻塞读取：使用 BRPOP； 重复消息处理：生产者自行实现全局唯一 ID； 消息的可靠性：使用 BRPOPLPUSH SetSet 类型的底层数据结构是由哈希表或整数集合实现的： 如果集合中的元素都是整数且元素个数小于 512 个，Redis 会使用整数集合作为 Set 类型的底层数据结构，反之则 Redis 使用哈希表作为 Set 类型的底层数据结构。 集合的主要几个特性，无序、不可重复、支持并交差等操作。 Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞。 在主从集群中，为了避免主库因为 Set 做聚合计算（交集、差集、并集）时导致主库被阻塞，我们可以选择一个从库完成聚合统计，或者把数据返回给客户端，由客户端来完成聚合统计。 应用抽奖活动（去重） 共同关注（交并集） Zset使用压缩列表或者跳表实现 当元素个数小于512的，且每个元素的值小于 64 字节时时候，使用压缩列表实现，反之使用跳表 应用排行榜（有序列表，且可以单独增加value的值，并且能查询区间） BitMapBitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。 String 类型是会保存为二进制的字节数组 123456# BitMap间的运算# operations 位移操作符，枚举值 AND 与运算 &amp; OR 或运算 | XOR 异或 ^ NOT 取反 ~ 应用 签到统计 判断用户登陆态 连续签到用户总数（与操作） HyperLogLogHyperLogLog 是统计规则是基于概率完成的，不是非常准确，标准误算率是 0.81%。提供不精确的去重计数。 应用统计网页访问者 GEO直接使用了 Sorted Set 集合类型。 应用查找以这个经纬度为中心的 5 公里内的车辆信息 StreamRedis Stream 是 Redis 5.0 版本新增加 在 Redis 5.0 Stream 没出来之前，消息队列的实现方式都有着各自的缺陷，例如： 发布订阅模式，不能持久化也就无法可靠的保存消息，并且对于离线重连的客户端不能读取历史消息的缺陷； List 实现消息队列的方式不能重复消费，一个消息消费完就会被删除，而且生产者需要自行实现全局唯一 ID。 基于 Stream 实现的消息队列 消息保序：XADD/XREAD 阻塞读取：XREAD block 重复消息处理：Stream 在使用 XADD 命令，会自动生成全局唯一 ID； 消息可靠性：内部使用 PENDING List 自动保存消息，使用 XPENDING 命令查看消费组已经读取但是未被确认的消息，消费者使用 XACK 确认消息； 支持消费组形式消费数据 但是与专业的消息队列对比，会存在丢消息的情况因为aof命令并不是先写到硬盘才写入到内存当中的 数据结构SDSc语言字符串缺陷：获取长度O(n):缓冲区溢出;不能保存二进制； SDS数据结构 以处理二进制的方式来处理 SDS 存放在 buf[] 里的数据 当发现缓冲区不够的时候会自动进行扩容，所需空间超过1MB，新长度为所需空间+1MB，反之新长度为所需空间的两倍 flags标志了不同长度和空间占用的字符串，可以减少头部长度 编译器优化，可以取消字节对齐 链表双向链表，封装了一层，增加了长度和其他节点比较函数、复制、释放 缺陷：链表通病 无法利用cpu缓存 节点结构头开销 持久化AOF 日志 redis 里的 AOF(Append Only File) 持久化功能，注意只会记录写操作命令，读操作命令是不会被记录的， 先写命令的好处 避免额外检查开销（记录到硬盘之前会先检查这个语法） 避免阻塞写命令 坏处 出现停电操作的时候，部分数据会丢失（和回写策略有关） 由于命令都是在主进程中执行，还是可能会阻塞下一个写命令 回写策略Always 每次写入 AOF 文件数据后，就执行 fsync() 函数 Everysec 创建一个异步任务来执行 fsync() 函数 No 永不执行 fsync() 函数 重写机制在使用重写机制后，就会读取 name 最新的 value（键值对） 重写过程由后台子进程进行操作，因为比较耗时避免阻塞主进程， 并且如果使用线程线程共享进程的资源，对共享内存进行读写的时候需要进行加锁，而父子进程，在创建时是共享数据的，但在修改的时候会生成自己的数据副本，写时复制 具体过程（虚拟空间不同，物理空间相同，标记该物理内存的权限为只读。） 主进程在子进程执行 AOF 重写期间，主进程需要执行以下三个工作: 执行客户端发来的命令； 将执行后的写命令追加到 「AOF 缓冲区」； 将执行后的写命令追加到 「AOF 重写缓冲区」； 在完成重写之后，主进程会收到信号， 将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致； 将新的aof重命名，并将后面所有的写命令记录到新的aof文件中 RDB文件save(主线程)和 bgsave(后台线程) 可以定时保存RDB文件，但是是一个比较重的方法频率得适当 保存快照的时候，数据被修改可以被修改，当主线程修改了某一块的数据就会发生写时复制，极端情况会发生内存会翻倍，写操作多的时候需要留意内存变化 混合持久化保存RDB并且在保存过程中的命令也会被写到重写缓冲区中最后以AOF的方式添加到末尾 对过期key的处理AOF写入阶段：创建的时候 直接增加key 过期删除的时候显示删除 del 重写阶段：会校验key的过期时间确保过期的key不会被写入到新的AOF文件当中 RDB写入阶段：会对key进行校验 加载阶段： 与主从服务器有关，如果是主服务器则不会加载，从服务器无论是否过期都会加载，但是在主从同步阶段就会被清空数据 缓存异常缓存雪崩缓存雪崩是指大量的应用请求无法在Redis缓存中进行处理，从而使得大量请求发送到数据库层，导致数据库压力过大甚至宕机。 同一时间缓存中的数据大面积过期（增加随机时间，设置热点数据永不过期，服务降级(非核心数据可以直接返回错误)） Redis 缓存实例发生故障宕机（前端限流，预防可部署高可用集群） 缓存击穿缓存击穿是指某个访问非常频繁的热点数据，大量并发请求集中在这一个点访问，在这个Key失效的瞬间，持续的大并发就穿破缓存，直接请求数据库 提前预热，设置热点数据永不过期 请求数据库写数据到缓存之前，先获取互斥锁，保证只有一个请求会落到数据库上，减少数据库的压力。 缓存穿透缓存穿透指用户要访问的数据既不在缓存中也不在数据库中，导致用户每次请求该数据时都要去数据库查一遍，然后返回空。 接口检验（用户鉴权，判断是否合法） 缓存空值或者缺省值（缓存空值可以设置过期时间） 布隆过滤器（布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在） 过期删除策略添加带有过期时间的key的时候，会把其key和过期时间加入到过期字典当中，查询时会先判断是否在过期字典当中 删除策略定时删除（设置key的时候，增加定时事件，定时删除；优点：内存友好；缺点：过期较多的时候会占用较多cpu时间） 惰性删除（不主动删除key，访问key时查询是否过期，然后再删除；优点：占用cpu资源少；缺点：内存不友好) 定期删除（每隔一段时间 清理一次过期key） Redis选择惰性+定期 定期删除是每隔一段时间「随机」从数据库中取出一定数量（20）的 key 进行检查，并删除其中的过期key,如果过期key超过25%，会继续进行新一轮的定期删除，如果执行时间超过25ms就不会执行新的一轮。 redis默认1s进行10次key过期检查 内存淘汰策略不淘汰 过期key里 随机 最早过期淘汰 lru lfu 所有key 随机 lru lfu","link":"/2023/06/19/redis/"},{"title":"framework","text":"MybatisMyBatis的$和#的区别1select * from user where name = #{name}; 解析为： 1select * from user where name = ?; 而${ } 仅仅为一个纯碎的 string 替换，在动态 SQL 解析阶段将会进行变量替换 sql注入user; delete user; ，那么就会删除整张表 Spring@Bean 和 @Component的区别是什么？ @Component 注解作用于类，而@Bean注解作用于方法。 @Bean 注解比 @Component 注解的自定义性更强 @Autowired 和 @Resource 的区别是什么？@Autowired 是 Spring 提供的注解，@Resource 是 JDK 提供的注解。 @autowired byType，@Qualifier（指定名称） @Resource byName（默认） Bean的作用域单例，prototype（每次一个），request（每个请求一个），每个session一个，global（一个web应用一个），一个websocket一个 单例bean的线程安全问题多个线程操作的是一个bean，避免可变的成员变量，需要的时候使用threadlocal Bean的生命周期 创建一个实例，调用构造方法 填充属性 设置beanName、beanFactory、ApplicationContext 前置处理 检查是否需要是初始化bean来决定调用afterPropertiesSet() init方法 后置处理 使用bean 执行disposableBean方法 destroy() IOC容器初始化过程 定位资源路径 构建ioc容器 解析xml文件 这一步是将document对象解析成spring内部的bean结构，实际上是AbstractBeanDefinition对象。 注册BeanDefition，实际上是放到一个ConcurrentMap里 循环依赖bean创建基本过程 实例化 createInstance，完成之后会加入三级缓存 属性注入 populateBean 如果依赖了其他的bean会从各级缓存中查找，如果在三级缓存中找到了，会将其放入二级缓存 初始化 initializeBean 会将bean加入到一级缓存，清除各级缓存 一级缓存中存储的是已经完全创建好了的单例Bean AOPAOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。 如果实现了某个接口就会使用jdk代理，如果没有就会使用cglib生成子类代理。 Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。 SpringMvc处理流程 http请求到DispatchServlet 查看配置的handlerMapping，查找对应处理器 调用适配处理器Adapter，适配处理器调用真正的handler handler返回modelAndView 调用视图处理器viewResolver 根据model渲染视图 返回结果","link":"/2023/06/15/framework/"},{"title":"消息队列","text":"消息队列的作用通过异步处理提高系统性能,减少响应时间 削峰填谷，缓解瞬时系统压力、提高系统资源利用 降低系统耦合性 消息队列会带来的问题系统复杂度提升（处理消息丢失、重复消费问题） 系统可用性降低（需要考虑消息丢失，MQ挂掉等问题) 一致性问题(异步处理问题) RocketMQ模式队列、主题、消息 一个 Topic 分布在多个 Broker上，一个 Broker 可以配置多个 Topic ，它们是多对多的关系。 一个主题有多个Message Queue 一个Message Queue只能对应一个消费者组中的消费者 角色 NameServer：邮局，Broker 管理 和 路由信息管理，每十秒检查一次，时间戳超过两分钟则认为broker失效（zookeeper功能太复杂了，nameserver无需选举、去中心化设计、更加轻量级） Broker：暂存者，生产者生产消息到 Broker ，消费者从 Broker 拉取消息并消费。 Consumer：收信者 Producer：发信者 broker 做了集群和主从，slave定时从master同步数据，从节点只读不写入消息 NameServer去中心化，在 RocketMQ 中是通过 单个 Broker 和所有 NameServer 保持长连接 ，并且在每隔 30 秒 Broker 会向所有 Nameserver 发送心跳 生产者从nameserver获取Broker信息，通过轮询的方式生产数据 向Broker发送pull来获取数据。可以用两种模式启动 广播（全部都发）和集群（其中一个） 顺序消费生产者： 保证消息发送到一个队列当中就可以。 如果要求全局顺序消息，那么只能设置一个读写队列 消费者： 防止并发消费，MessageListenerOrderly ，会为每个consumerqueue加锁 重复消费实现幂等，使用redis或者数据库唯一键来保证不会重复。 消息堆积判断是不是生产的太快，限流降级，增加消费者或者增加消费速度 判断是不是消费的太慢，可能是消费错误，排查下日志 分布式事务 发送half消息 返回确认消息 系统执行事务 发送commit或者Rollback消息 如果因为网络原因未收到，则会发送事务反查 检查事务状态 发送commit或者Rollback消息 同步刷盘和异步刷盘 不同点：同步刷盘需要等待刷盘完成然后才能发送成功状态，异步刷盘需要开启另一个线程去刷盘，写线程可以直接返回，提高吞吐量，可以积累一定量的消息统一触发写磁盘任务。异步刷盘会在broker意外宕机的时候才会丢失部分数据。 内存一般指的是页缓存 当用户在读写数据的时候，内核会申请一个内存页与文件中的数据块进行绑定 用户对文件的读写实际上是对页缓存的读写，如果读的数据已经存在页缓存当中，就不用在进行读取，否则就会申请一个新的内存页，进行读取数据然后复制给用户；写操作也相同。 同步复制和异步复制Borker 主从模式 同步复制是等 Master 和 Slave 均写成功后才反馈给客户端写成功状态； 异步复制是只要 Master 写成功即可反馈给客户端写成功状态 。 异步复制并不会影响消息的可靠性，主节点宕机，从节点只是会缺少部分消息，在主节点下次重启的时候消息就会重新发送过来。 MQ存储机制commitLog：消息主体以及元数据保存主体 ConsumeQueue：消费队列，主要是为了提高消费性能，保存了指定topic下的offset、size、tag的哈希值，存储路径$HOME/store/consumequeue/{topic}/{queueId}/{fileName} IndexFile：索引文件，可以通过 key 或时间区间来查询消息 先将消息发到全部发送到CommitLog，并通过topic和queueId将commitLog中的offset、消息大小和tag的hashcode一起发送到consumerQueue中，消费者只需要获取consumerOffset获取对应位置的commitLogOffset即可获取到原始信息。","link":"/2023/06/26/MQ/"}],"tags":[{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"HashMap","slug":"HashMap","link":"/tags/HashMap/"},{"name":"Blog","slug":"Blog","link":"/tags/Blog/"},{"name":"Greedy","slug":"Greedy","link":"/tags/Greedy/"},{"name":"MergeSort","slug":"MergeSort","link":"/tags/MergeSort/"},{"name":"DynamicProgramming","slug":"DynamicProgramming","link":"/tags/DynamicProgramming/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"java，concurrent","slug":"java，concurrent","link":"/tags/java%EF%BC%8Cconcurrent/"},{"name":"network","slug":"network","link":"/tags/network/"},{"name":"Mysql","slug":"Mysql","link":"/tags/Mysql/"},{"name":"jvm","slug":"jvm","link":"/tags/jvm/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"mybatis","slug":"mybatis","link":"/tags/mybatis/"},{"name":"MQ","slug":"MQ","link":"/tags/MQ/"}],"categories":[{"name":"Algorithm","slug":"Algorithm","link":"/categories/Algorithm/"},{"name":"Blog","slug":"Blog","link":"/categories/Blog/"},{"name":"java","slug":"java","link":"/categories/java/"},{"name":"concurrent","slug":"concurrent","link":"/categories/concurrent/"},{"name":"network","slug":"network","link":"/categories/network/"},{"name":"Mysql","slug":"Mysql","link":"/categories/Mysql/"},{"name":"jvm","slug":"jvm","link":"/categories/jvm/"},{"name":"spring","slug":"spring","link":"/categories/spring/"},{"name":"redis","slug":"redis","link":"/categories/redis/"},{"name":"mybatis","slug":"spring/mybatis","link":"/categories/spring/mybatis/"},{"name":"MQ","slug":"MQ","link":"/categories/MQ/"}],"pages":[]}