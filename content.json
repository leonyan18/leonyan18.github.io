{"posts":[{"title":"牛客模拟缓存","text":"BM100 设计LRU缓存结构题意链接：设计LRU缓存结构_牛客题霸_牛客网 (nowcoder.com) 思路linkedHashMap可以维护元素插入顺序或者元素访问顺序，那么第一个元素即为最远没有访问过的， set和get在通常情况是O(1),最坏情况是O(logn) 使用LinkedHashMap设置为访问次序 set的时候要注意容量，移除最久未使用的key 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.yan.simulation;import com.yan.base.Solution;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.io.InputStream;import java.io.OutputStream;import java.util.LinkedHashMap;//@Servicepublic class LRUCacheSolution implements Solution { private LinkedHashMap&lt;Integer,Integer&gt; map; private int capacity; @Override public void solve(InputStream in, OutputStream outputStream) { System.out.println(&quot;test&quot;); LRUCacheSolution lruCacheSolution=new LRUCacheSolution(2); lruCacheSolution.set(1,1); lruCacheSolution.set(2,2); System.out.println(lruCacheSolution.get(1)); lruCacheSolution.set(3,3); System.out.println(lruCacheSolution.get(2)); lruCacheSolution.set(4,4); System.out.println(lruCacheSolution.get(1)); System.out.println(lruCacheSolution.get(3)); System.out.println(lruCacheSolution.get(4)); } public LRUCacheSolution() { } public LRUCacheSolution(int capacity) { this.capacity=capacity; // 设置为访问顺序 map= new LinkedHashMap&lt;&gt;(capacity,0.75f,true); // write code here } public int get(int key) { if (!map.containsKey(key)){ return -1; } int val=map.get(key); return val; } public void set(int key, int value) { // 只有大小等于容量并且插入的时候key不存在的时候才进行删除之前的 if(map.size()==capacity&amp;&amp;!map.containsKey(key)){ // 删除最远没用过的 int temp= map.entrySet().iterator().next().getKey(); map.remove(temp); } map.put(key,value); }} BM101 设计LFU缓存结构题意 思路个人思路（非最佳）使用优先队列，记录查找和查询次数以及相对位置，按照次数最少排序，使用懒删除的思想在容量满的时候才对前面的元素去除脏数据 使用数据结构 12345678910 private HashMap&lt;Integer, Integer&gt; map;// key -value private HashMap&lt;Integer, Integer&gt; countMap;// key -次数 private HashMap&lt;Integer, Integer&gt; opMap;// key -操作数 private int capacity; // 容量 private int op;// 操作数class Node { int key; int cnt; int pos; } 插入时： 容量为满的的时候，会先查询队首元素是否为正确节点步骤如下 判断这个节点是否正确的操作数 判断这个节点是否已删除 不正确的话就弹出节点，并重复操作，直至正确。countMap和map中回删除这个key； 插入和获取节点，countMap，map和queue更新数据，同时op操作数++ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140package com.yan.simulation;import com.yan.base.Solution;import org.springframework.stereotype.Service;import java.io.InputStream;import java.io.OutputStream;import java.util.*;@Servicepublic class LFUCacheSolution implements Solution { private HashMap&lt;Integer, Integer&gt; map; private HashMap&lt;Integer, Integer&gt; countMap; private HashMap&lt;Integer, Integer&gt; opMap; private int capacity; private int op; private PriorityQueue&lt;Node&gt; queue; @Override public void solve(InputStream in, OutputStream outputStream) { LFUCacheSolution lfuCacheSolution = new LFUCacheSolution(3); lfuCacheSolution.set(2054879058, -121373736); lfuCacheSolution.set(2054879053, -121373736); lfuCacheSolution.set(2054879025, -121373736); lfuCacheSolution.set(2, 4); lfuCacheSolution.set(3, 5); System.out.println(lfuCacheSolution.get(2)); lfuCacheSolution.set(4, 4); System.out.println(lfuCacheSolution.get(1)); } public int[] LFU(int[][] operators, int k) { ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; operators.length; i++) { if (operators[i][0] == 1) { set(operators[i][1], operators[i][2]); } else { int temp = get(operators[i][1]); arrayList.add(temp); } } int[] d = new int[arrayList.size()]; for (int i = 0; i &lt; arrayList.size(); i++) { d[i] = arrayList.get(i); } return d; } public LFUCacheSolution() { } public LFUCacheSolution(int capacity) { this.capacity = capacity; map = new HashMap&lt;&gt;(capacity); countMap = new HashMap&lt;&gt;(capacity); opMap = new HashMap&lt;&gt;(capacity); queue = new PriorityQueue&lt;&gt;(capacity * 4, new Comparator&lt;Node&gt;() { @Override public int compare(Node o1, Node o2) { if (o1.cnt != o2.cnt) { return o1.cnt - o2.cnt; } else { return o1.pos - o2.pos; } } }); } public int get(int key) { if (!map.containsKey(key)) { return -1; } int val = map.get(key); int cnt = countMap.get(key); countMap.put(key, cnt + 1); opMap.put(key, op); queue.add(new Node(key, cnt + 1, op)); op++; return val; } public void set(int key, int value) { // 只有大小等于容量并且插入的时候key不存在的时候才进行删除之前的 if (map.size() == capacity &amp;&amp; !map.containsKey(key)) { // 删除最远没用过的 Node temp = queue.peek(); while (!map.containsKey(temp.key) || (temp.pos != opMap.get(temp.key))) { queue.poll(); temp = queue.peek(); } temp=queue.poll(); map.remove(temp.key); countMap.remove(temp.key); } map.put(key, value); countMap.put(key, 1); opMap.put(key, op); queue.add(new Node(key, 1, op)); op++; } class Node { int key; int cnt; int pos; public Node() { } public Node(int key, int cnt, int pos) { this.key = key; this.cnt = cnt; this.pos = pos; } @Override public boolean equals(Object o) { if (this == o) return true; if (!(o instanceof Node)) return false; Node node = (Node) o; if (key != node.key) return false; if (cnt != node.cnt) return false; return pos == node.pos; } @Override public int hashCode() { int result = key; result = 31 * result + cnt; result = 31 * result + pos; return result; } }} 题解思路题解 | #设计LFU缓存结构#_牛客博客 (nowcoder.net) 需要在O(1)时间内实现两个操作，我们第一时间想到的还是哈希表，利用哈希表保存LFU的key值，而哈希表的value值对应了另一边存着每个缓存需要的类的节点，这样就实现了直接访问。 但是我们还需要每次最快找到最久未使用的频率最小的节点，这时候我们可以考虑使用一个全局变量，跟踪记录最小的频率，有了最小的频率（当你使用set方法的时候每次进来的都是最小频率的，所以需要更新的时候通常更新为1，或者频率为最小频率的没有了进行++操作），怎样直接找到这个频率最小的节点，还是使用哈希表，key值记录各个频率，而value值就是后面接了一串相同频率的节点。如何保证每次都是最小频率的最久为使用，我们用双向链表将统一频率的节点连起来就好了，每次新加入这个频率的都在链表头，而需要去掉的都在链表尾。 算法全部代码参考leonyan18/AlgorithmCodeInJava (github.com)","link":"/2022/12/26/NowcoderEmulateCache/"},{"title":"Hexo博客搭建以及文件同步","text":"总体结构 Hexo+ Icarus主题作为博客基础，在此基础对此主题进行布局修改 修改和发布文章，一开始是采用了hexo-admin的方式进行修改的，后面感觉还是麻烦和本地typora差距甚大，于是使用了Alist和RaiDrive进行本地挂载远程目录的方式，并结合图床。 博客搭建hexo文档 | Hexo 安装 Hexo 需要先安装下列应用程序即可： Node.js (Node.js 版本需不低于 10.13，建议使用 Node.js 12.0 及以上版本) Git 1234#全局安装npm install -g hexo-cli#局部安装npm install hexo hexo主题Icarusgithub地址ppoffice/hexo-theme-icarus: A simple, delicate, and modern theme for the static site generator Hexo. (github.com) 文档地址Icarus快速上手 - Icarus (ppoffice.github.io) 不过个人推荐可以安装之前的库如4.4版本的，5.0以上版本布局都不在themes/Icarus/layout/下了,都在node_modules里了，后面修改原来的布局就十分麻烦 12npm install hexo-theme-icarushexo config theme icarus 配置文件可以参考自动生成的_config.icarus.yml.example，以及对应的文档Tag: Icarus用户指南 - Icarus (ppoffice.github.io) 布局问题参考链接Hexo主题Icarus的自定义 - Astroblog (astrobear.top) 由于原来看文章的时候多栏布局导致文章内容过于窄了所以第一步需要先改成双栏 还需要新建一个文章的单独布局_config.post.yml代码如下，即所有widget都在左或者右边 12345678910111213141516171819202122sidebar: left: sticky: true right: sticky: falsewidgets: - position: left type: profile author: 颜晨曦 author_title: 研究生 location: 浙江 台州 avatar: /img/avatar.png avatar_rounded: false gravatar: follow_link: https://github.com/leonyan18 - position: left type: toc index: true collapsed: true depth: 6 还有一个问题就是文章内容宽度还是偏窄，之前版本的修改方法现在都要里面的文件对应到node_modules/hexo-theme-Icarus中文件进行修改，然后重新设置主题，并重启。 之前方法参考链接Hexo主题Icarus的自定义 - Astroblog (astrobear.top)，将 Icarus5的优雅替代方法主要还是强迫症，怕以后备份的时候忘记node_modules里的东西，要重新修改布局一遍 将node_modules/hexo-theme-Icarus中的文件复制到最外层主题themes/icarus/中（没有就创建），那么其实你就相当于创建了一个和Icarus一模一样的主题，和之前Icarus4的做法一样，直接在这里面改动就行。 文件同步参考一下之前的文章Alist+RaiDrive+阿里云盘=本地网盘+文件实时同步+备份 - blog (dawnchannel.tech) 使用Alist添加本地存储(博客目录/source/_posts/) RaiDrive就会映射到本地盘中 博客编写安装typoraTypora — a markdown editor, markdown reader. 使用picGo作为图床，添加你有的图床，我是用的minio图床，需要在里面下载一个插件即可 然后在Typora中进行配置，配置完成之后你的复制的图片点击上传就能上传到图床之上","link":"/2022/12/27/blog/"},{"title":"Alist+RaiDrive+阿里云盘&#x3D;本地网盘+文件实时同步+备份","text":"总体结构 远程存储空间为服务器上指定目录和阿里云盘指定目录 Alist作为文件管理工具，并向RaiDrive 提供 webDAV接口 Rai作为本地挂载远程工具的软件，使原本需要读取远程文件的操作像本地操作一样简单 Alist安装以及使用先看官方文档一键脚本 | AList文档 (nn.ci) 本人使用官方推荐的这个脚本安装 123456#安装curl -fsSL &quot;https://alist.nn.ci/v3.sh&quot; | bash -s install#更新curl -fsSL &quot;https://alist.nn.ci/v3.sh&quot; | bash -s update#卸载curl -fsSL &quot;https://alist.nn.ci/v3.sh&quot; | bash -s uninstall 一键脚本安装之后，默认安装在/opt/alist 后续获得管理员密码要从手动安装的运行里面找，这个一开始我也没找到 123456# 进入文件夹cd /opt/alist# 运行程序./alist server# 获得管理员信息./alist admin 管理员登录 然后就是在web页面上操作了，默认是5244端口，服务器的话需要安全组开端口 之后看文档解决一下通用项 | AList文档 (nn.ci) 添加服务器本地存储本地存储 | AList文档 (nn.ci)，可以日后作为服务器和本地实时同步文件，带宽不高就要用来看视频了 添加阿里云盘阿里云盘 | AList文档 (nn.ci)，可以它用他看视频听歌，切记切记WebDAV 策略使用302重定向，这样用的就不是你服务器的带宽了，而是阿里云盘的 这些文档都讲的比较清晰了，就不再赘述 Rai软件安装下载链接：下载 (raidrive.com.cn) 直接点击安装就行，期间会有安装其他软件和一些设备软件，安装就行 然后点击添加，选择NS webDAV 然后就行了","link":"/2022/12/28/local_sync/"},{"title":"使用Github Actions 动态更新Github主页","text":"总体思路借鉴思路地址使用Github Actions 动态更新Github主页 - 方圆小站 (fangyuanxiaozhan.com) 原文讲的东西不够全，我这会补充一点 项目参考地址leonyan18/leonyan18 (github.com) python脚本爬取博客更新内容，并写入更新到指定位置 github action 每天定时启动这个任务 python脚本第一步是选择你要插入的位置，并修改脚本12345678910111213这是我的ReadME.md## Recent Blog Posts(update time:2022-12-29 10:15:20)[Alist+RaiDrive+阿里云盘&amp;#x3D;本地网盘+文件实时同步+备份](http://dawnchannel.tech/2022/12/28/local_sync/)[Hexo博客搭建以及文件同步](http://dawnchannel.tech/2022/12/27/blog/)[牛客模拟缓存](http://dawnchannel.tech/2022/12/26/NowcoderEmulateCache/)&lt;br/&gt;## 💻:keyboard: Languages and Tools 我是在## Recent Blog Posts和## 💻:keyboard: Languages and Tools 之间进行插入的，根据实际情况替换值，我这边是多了几个回车，需要注意一下，在本地调试通过之后在进行上传。 在main.py对应位置进行修改，在两个insert_info = 的位置 第二步 根据实际返回修改get_link_info函数由于本人是通过hexo+icarus主题实现的，博客内容可以通过http://dawnchannel.tech/content.json直接获得，可以将其替换成自己的地址。 其他地址需要个人自定义了，还要注意一点我这个是按照时间顺序下来的，所以我还进行了一个逆序操作。 1234567891011121314151617181920212223242526272829303132333435363738394041import timeimport osimport reimport pytzimport requestsimport jsonfrom datetime import datetimedef get_link_info(feed_url, num): result = &quot;&quot; response = requests.get(feed_url).text response=json.loads(response) feed_entries = response[&quot;posts&quot;] feed_entries.reverse() feed_entries_length = len(feed_entries) all_number = 0 if(num &gt; feed_entries_length): all_number = feed_entries_length else: all_number = num for entrie in feed_entries[0: all_number]: title = entrie[&quot;title&quot;] link = &quot;http://dawnchannel.tech&quot;+entrie[&quot;link&quot;] result = result + &quot;\\n&quot; + &quot;[&quot; + title + &quot;](&quot; + link + &quot;)&quot; + &quot;\\n&quot; return resultdef main(): insert_info = get_link_info(&quot;http://dawnchannel.tech/content.json&quot;, 6) # 替换 ---start--- 到 ---end--- 之间的内容 # pytz.timezone('Asia/Shanghai')).strftime('%Y年%m月%d日%H时M分') fmt = '%Y-%m-%d %H:%M:%S %Z%z' insert_info = &quot;## Recent Blog Posts(&quot; + &quot;update time:&quot;+ datetime.fromtimestamp(int(time.time()),pytz.timezone('Asia/Shanghai')).strftime('%Y-%m-%d %H:%M:%S') +&quot;)\\n&quot; + insert_info + &quot;\\n\\n&lt;br/&gt;\\n\\n## 💻:keyboard: Languages and Tools &quot; # 获取README.md内容 print(insert_info) with open (os.path.join(os.getcwd(), &quot;README.md&quot;), 'r', encoding='utf-8') as f: readme_md_content = f.read() new_readme_md_content = re.sub(r'## Recent Blog Posts(.|\\n)*## 💻:keyboard: Languages and Tools ', insert_info, readme_md_content) with open (os.path.join(os.getcwd(), &quot;README.md&quot;), 'w', encoding='utf-8') as f: f.write(new_readme_md_content)main() 第三步 本地调试主要测试一下，本地的ReadME文件是否正常，在没有最近博客的时候和有最近博客的时候都测试一下。 github actions前期准备先解释下action的流程 创建所需要的环境 安装对应依赖 git操作 然后看下我们的目录结构以及所需要的东西，缺一样都不可以 ReadMe.md ，主要需要修改的对象 main.py，python脚本用于修改内容 Pipfile，创建环境安装对应依赖 .gitignore，忽略生成的其他无关文件 .gitignore和Pipfile文件直接使用参考仓库里，如果用到其他库或者新增其他文件了，请自行添加。 启动actions点击仓库下面的actions按钮，创建对应main.yml 1234567891011121314151617181920212223242526272829303132name: 'leonyan18'on: push: schedule: - cron: '0 1 * * *'jobs: stale: runs-on: ubuntu-latest strategy: matrix: # in this example, there is a newer version already installed, 3.7.7, so the older version will be downloaded python-version: ['3.7.4'] steps: - uses: actions/checkout@v2 # Checking out the repo - name: Install dependecies uses: VaultVulp/action-pipenv@v2.0.1 with: command: install -d # Install all dependencies, including development ones - name: Build uses: VaultVulp/action-pipenv@v2.0.1 with: command: run build - name: Commit and push if changed # 更新README.md run: | git diff git config --global user.email &quot;1183503933@qq.com&quot; git config --global user.name &quot;leonyan&quot; git add README.md git commit -m &quot;Github Action Auto Updated&quot; git push 提交之后，去Enable这个job就可以每天更新了。 注意当你重新启动失败的job的时候，一定要手动触发，重新运行之前的已经不行了，因为readme已经被修改过了，可以通过重新git提交会自动触发 或者改为手动触发 123on: # 手动触发事件 workflow_dispatch:","link":"/2022/12/29/GetRecentBlog/"},{"title":"BM95 分糖果问题","text":"题意链接：分糖果问题_牛客题霸_牛客网 (nowcoder.com) 思路题意可得 极小值点只给一颗糖。 如果左边都比右边小那么是个单调递增序列，且差值为1。如果左边都比右边大就可同理得。 如果相等的话，只考虑不相等一边的情况，如果都相等则为1。 将数组拆分一段又一段的单调序列话，就剩下一个极大值点需要讨论 如果比左右两边都大，要同时满足左右两边的这点的糖果数就取决于左右两边谁需求的糖果数大了。 一开始我的思路，找单调递增和递减的长度，算一个等差数列，打算扫一遍算出来，但是后来想想好像情况有点复杂，总共有四种情况，比两边都大的点，即极大值点还要去遍历右边才能知道他的值，这样的话就是O(n^2),显然不行 优化方法就是从左往右和从左往右都扫一遍，每次只算一边的情况，然后取极大值。 具体步骤 从左边开始扫，如果左边比他大，那么糖果数=左边糖果数+1，反之为1。糖果数组记为candyL 从右边开始扫，如果右边比他大，那么糖果数=右边糖果数+1，反之为1。糖果数组记为candyR 从左边开始累加max(candyL[i],candyR[i]),最后输出 代码如下 123456789101112131415161718192021222324252627282930public int candy(int[] arr) { // write code here int ans = 0; int[] candyl=new int[arr.length+5]; int[] candyr=new int[arr.length+5]; int pre=arr[0]; candyl[0]=1; candyr[arr.length-1]=1; for (int i = 1; i &lt; arr.length; i++) { if(arr[i]&gt;pre){ candyl[i]=candyl[i-1]+1; }else { candyl[i]=1; } pre=arr[i]; } pre=arr[arr.length-1]; for (int i = arr.length-2; i &gt;= 0; i--) { if(arr[i]&gt;pre){ candyr[i]=candyr[i+1]+1; }else { candyr[i]=1; } pre=arr[i]; } for (int i=0;i&lt;arr.length;i++){ ans+=Math.max(candyl[i],candyr[i]); } return ans; } 算法全部代码参考leonyan18/AlgorithmCodeInJava (github.com)","link":"/2022/12/30/BM95/"},{"title":"数组中的逆序对","text":"数组中的逆序对_牛客题霸_牛客网 (nowcoder.com) 题意 思路尝试：每次看到这个题，我都老是想记录原来位置然后再排个序看看和原来的差值，即是答案。后面想想快速排序试试，移到前面的+上差值，移到后面的减去差值，中间过程不一定就是差值。 ​ 使用归并排序，排序过程中，逆序对会随着元素慢慢移到正确的位置而减少，而且每次减少的逆序对是可以统计的。将两个有序数组进行合并的时候，当右数组的元素移动到左数组的原来位置的时候，减少的逆序对数为移动距离，记录该值即可。 ​ 至于取余的问题每次都进行cnt=(cnt+mod)%mod就可以了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public long cnt = 0; public long mod = 1000000007; public void Merge(int[] array, int[] temp, int l, int r) { if(l&gt;=r) return; int mid=(l+r)/2; int pos=l,lpos=l,rpos=mid+1; while (lpos&lt;=mid&amp;&amp;rpos&lt;=r) { if (array[lpos]&lt;=array[rpos]){ temp[pos]=array[lpos]; lpos++; }else { temp[pos]=array[rpos]; cnt+=rpos-pos; cnt=(cnt+mod)%mod; rpos++; } pos++; } while(lpos&lt;=mid){ temp[pos]=array[lpos]; lpos++; pos++; } while(rpos&lt;=r){ temp[pos]=array[rpos]; rpos++; pos++; } for (int i = l; i &lt;= r; i++) { array[i]=temp[i]; } } public void MergeSort(int[] array, int[] temp, int l, int r) { int cnt; if (l &gt;= r) return; int mid = (l + r) / 2; MergeSort(array, temp, l, mid); MergeSort(array, temp, mid + 1, r); Merge(array,temp, l, r); } public int InversePairs(int[] array) { cnt = 0; int[] temp = new int[array.length]; MergeSort(array, temp, 0, array.length - 1); return (int) cnt; } 算法全部代码参考leonyan18/AlgorithmCodeInJava (github.com)","link":"/2023/01/01/BM20/"},{"title":"BM75 编辑距离(一)","text":"题意编辑距离(一)_牛客题霸_牛客网 (nowcoder.com) 思路主要难点是如何建立dp数组，我当时想的是（i，j）表示的是i和j的区间已经完成操作，但是递推方程需要左边和右边都有，所以不行后续的j表示长度的话也不行。忘得太快了。。。。 题解 | #编辑距离(一)#_牛客博客 (nowcoder.net) 把第一个字符串变成第二个字符串，我们需要逐个将第一个字符串的子串最少操作下变成第二个字符串，这就涉及了第一个字符串增加长度，状态转移，那可以考虑动态规划。用dp[i][j]表示从两个字符串首部各自到str1[i]和str2[j]为止的子串需要的编辑距离，那很明显dp[str1.length][str2.length]就是我们要求的编辑距离。（下标从1开始） 具体做法： step 1：初始条件： 假设第二个字符串为空，那很明显第一个字符串子串每增加一个字符，编辑距离就加1，这步操作是删除；同理，假设第一个字符串为空，那第二个字符串每增加一个字符，编辑距离就加1，这步操作是添加。 step 2：状态转移： 状态转移肯定是将dp矩阵填满，那就遍历第一个字符串的每个长度，对应第二个字符串的每个长度。如果遍历到str1[i]和 str2[j]的位置，这两个字符相同，这多出来的字符就不用操作，操作次数与两个子串的前一个相同，因此有dp[i][j]=dp[i-1][j-1]；如果这两个字符不相同，那么这两个字符需要编辑，但是此时的最短的距离不一定是修改这最后一位，也有可能是删除某个字符或者增加某个字符，因此我们选取这三种情况的最小值增加一个编辑距离，即dp[i][j]=min(dp[i-1][j-1],dp[i][j-1],dp[i][j])+1。 123456789101112131415161718192021222324public int editDistance(String str1, String str2) { // write code here int len1 = str1.length(); int len2 = str2.length(); int[][] dp = new int[len1 + 5][len2 + 5]; for (int i = 0; i &lt;= len1; i++) { dp[i][0] = i; } for (int i = 0; i &lt;= len2; i++) { dp[0][i] = i; } for (int i = 1; i &lt;= len1; i++) { for (int j = 1; j &lt;= len2; j++) { if (str1.charAt(i - 1) == str2.charAt(j - 1)) { dp[i][j] = dp[i - 1][j - 1]; } else { dp[i][j] = dp[i - 1][j - 1] + 1; dp[i][j] = Math.min(dp[i - 1][j] + 1, dp[i][j]); dp[i][j] = Math.min(dp[i][j - 1] + 1, dp[i][j]); } } } return dp[len1][len2]; } 算法全部代码参考leonyan18/AlgorithmCodeInJava (github.com)","link":"/2023/01/06/BM75/"},{"title":"Java问题收集","text":"理解原码、反码、补码、移码 符号位：0位正数，1为负数 原码不能进行运算 正数的原码和反码一样，负数的反码是在原码的基础上，符号位不变，其余取反 正数的补码和反码一样，负数的补码是在反码的基础上进行＋1操作 移码是在补码的基础上，把符号位取反 1 -1 1+（-1） 结果 原码 0000 0001 1000 0001 1000 0010 -2 反码 0000 0001 1111 1110 1111 1111 -0 补码 0000 0001 1111 1111 0000 0000 +0 移码 1000 0001 0111 1111 1000 0000 0 取值范围 整数 n=8 原码 -(2^(n-1)-1)~2^(n-1)-1 -127~127 反码 -(2^(n-1)-1)~2^(n-1)-1 -127~127 补码 -2^(n-1)~2^(n-1)-1 -128~127 StringJava 9 为何要将 String 的底层实现由 char[] 改成了 byte[] ?JEP 254： 紧凑字符串 (openjdk.org) 我们建议更改类的内部表示 从 UTF-16 数组到数组加上编码标志字段。 新类将存储编码为 ISO-8859-1/Latin-1（每个字符一个字节），或 UTF-16（每个字符两个字节） 字符） 字符串拼接用“+” 还是 StringBuilder?可以从字节码里看出 字符串对象通过“+”的字符串拼接方式，实际上是通过 StringBuilder 调用 append() 方法实现的，拼接完成之后调用 toString() 得到一个 String 对象 。 不过，在循环内使用“+”进行字符串的拼接的话，存在比较明显的缺陷：编译器不会创建单个 StringBuilder 以复用，会导致创建过多的 StringBuilder 对象。 著作权归所有 原文链接：https://javaguide.cn/java/basis/java-basic-questions-02.html Java代理反射优缺点优点 ： 可以让咱们的代码更加灵活、为各种框架提供开箱即用的功能提供了便利 缺点 ：让我们在运行时有了分析操作类的能力，这同样也增加了安全问题。比如可以无视泛型参数的安全检查（泛型参数的安全检查发生在编译时）。另外，反射的性能也要稍差点，不过，对于框架来说实际是影响不大的。 著作权归所有 原文链接：https://javaguide.cn/java/basis/reflection.html 反射为什么慢Reflection is slow for a few obvious reasons: The compiler can do no optimization whatsoever as it can have no real idea about what you are doing. This probably goes for the JIT as well Everything being invoked/created has to be discovered (i.e. classes looked up by name, methods looked at for matches etc) Arguments need to be dressed up via boxing/unboxing, packing into arrays, Exceptions wrapped in InvocationTargetExceptions and re-thrown etc. All the processing that Jon Skeet mentions here. performance - Java Reflection: Why is it so slow? - Stack Overflow 静态代理需要手动实现一个代理类，实际应用中较少 JDK 动态代理和 CGLIB 动态代理对比 JDK 动态代理只能代理实现了接口的类或者直接代理接口，而 CGLIB 可以代理未实现任何接口的类。 另外， CGLIB 动态代理是通过生成一个被代理类的子类来拦截被代理类的方法调用，因此不能代理声明为 final 类型的类和方法。 就二者的效率来说，大部分情况都是 JDK 动态代理更优秀，随着 JDK 版本的升级，这个优势更加明显。 著作权归所有 原文链接：https://javaguide.cn/java/basis/proxy.html 静态代理和动态代理的对比 灵活性 ：动态代理更加灵活，不需要必须实现接口，可以直接代理实现类，并且可以不需要针对每个目标类都创建一个代理类。另外，静态代理中，接口一旦新增加方法，目标对象和代理对象都要进行修改，这是非常麻烦的！ JVM 层面 ：静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。而动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。 著作权归所有 原文链接：https://javaguide.cn/java/basis/proxy.html BigDecimal浮点数之间的等值判断，基本数据类型不能用 == 来比较，包装数据类型不能用 equals 来判断。 我们在使用 BigDecimal 时，为了防止精度丢失，推荐使用它的BigDecimal(String val)构造方法或者 BigDecimal.valueOf(double val) 静态方法来创建对象。 大小比较使用 a.compareTo(b)， equals() 方法不仅仅会比较值的大小（value）还会比较精度（scale），而 compareTo() 方法比较的时候会忽略精度。 著作权归所有 原文链接：https://javaguide.cn/java/basis/bigdecimal.html","link":"/2023/02/20/JavaProblem/"},{"title":"Java集合","text":"参考https://javaguide.cn/ ArrayList构造函数 校验初始容量 如果是无参构造，那么还是赋值一个空的数组，但是插入的时候会辨别;反之则构造一个空的数组DEFAULTCAPACITY_EMPTY_ELEMENTDATA，但是下次扩容会取最小扩容量与默认初始化长度（一般为10）进行比较。 扩容过程add函数校验大小获取最少需要长度通常是插入数量+当前长度， grow函数如果不够就进行扩容，并确定扩容大小，每次扩容变成原来的1.5倍，0.5倍由无符号右移一位得到，新长度有最少需要长度与原来长度的1.5倍的最大值得到，但是不超过SOFT_MAX_ARRAY_LENGTH，该值为Int的最大值-8，是由于部分java虚拟机需要存放object header会导致堆栈溢出，Java中的对象头信息（数组长度）需要占用8个字节的空间，所以选择了个略小于最大值的值。 Arrays.copyOf(elementData, newCapacity);将元素赋值到新地方 HashMapTableSizeFor()通过-1无符号右移给定容量的前导零长度+1得到最接近的2幂次-1，同时与最大容量进行比较 12int n = -1 &gt;&gt;&gt; Integer.numberOfLeadingZeros(cap - 1);return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; 构造函数给定的默认容量为 16，负载因子为 0.75。 参数带容量或者负载因子那就需要TableSizeFor()函数确定table大小 哈希方法12345//JDK1.7h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12);return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);//JDK1.8return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); 定位方法(n - 1) &amp; hash n为哈希表长度 put 方法首先判断数组是否经过初始化，如果没有则需要进行初始化 定位数组位置，如果无节点，则直接插入,并检验容量是否达到上限 如果存在相同的key，则直接覆盖并返回，因为没有节点增加 如果该节点是树节点，则使用红黑树的方法插入 如果该节点是普通链表节点，插入节点先判断插入后（链表长度大于阈值（默认为 8）并且 HashMap 数组长度超过 64 的时候才会执行链表转红黑树的操作，否则就只是对数组扩容） resize()方法容量参数设置首先判断原来的table是否为空，为空则进行初始化，如果也没有指定loadFactor和threshold则使用默认的， 如果不为空，容量变为原来的两倍。 同时更新threshold参数，并开辟新的node数组空间 进行迁移如果table为空，直接跳过。 遍历node数组{ ​ 如果只有一个元素，则newTab[e.hash &amp; (newCap - 1)] = e; ​ 如果是红黑树，会遍历红黑树，根据e.hash &amp; oldCap的值区分不同的位置(在原来位置j，还是j+oldcap)，且当拆分开的红黑树的节点数小于6的时候会变成链表插入到node数组中 ​ 链表同理，遍历链表根据e.hash &amp; oldCap的值区分不同的位置(在原来位置j，还是j+oldcap) } ConcurrentHashMap翻了ConcurrentHashMap1.7 和1.8的源码，我总结了它们的主要区别。 - 掘金 (juejin.cn) 1.7 segment+hashentry +链表的形式 ConcurrnetHashMap 由很多个 Segment 组合，而每一个 Segment 是一个类似于 HashMap 的结构，所以每一个 HashMap 的内部可以进行扩容。但是 Segment 的个数一旦初始化就不能改变，默认 Segment 的个数是 16 个，你也可以认为 ConcurrentHashMap 默认支持最多 16 个线程并发 默认初始化容量16;默认负载因子 0.75f;默认并发级别16; 1.8(38条消息) ConcurrentHashMap底层详解(图解扩容)（JDK1.8）_concurrenthashmap扩容_编程芝士的博客-CSDN博客 1234static final int MOVED = -1; // hash for forwarding nodesstatic final int TREEBIN = -2; // hash for roots of treesstatic final int RESERVED = -3; // hash for transient reservationsstatic final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash 变量sizeCtl -1 说明正在初始化，如果发现正在初始化Thread.yield(); -N 说明有N-1个线程正在进行扩容 0 表示 table 初始化大小，如果 table 没有初始化 &gt;0 表示 table 扩容的阈值，如果 table 已经初始化。 初始化表1234567891011121314151617181920212223242526private final Node&lt;K,V&gt;[] initTable() { Node&lt;K,V&gt;[] tab; int sc; // 类似CAS方法 循环初始化表 while ((tab = table) == null || tab.length == 0) { if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin // CAS else if (U.compareAndSetInt(this, SIZECTL, sc, -1)) { try { // 检查表是否初始化 if ((tab = table) == null || tab.length == 0) { int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; // 0.75 sc = n - (n &gt;&gt;&gt; 2); } } finally { sizeCtl = sc; } break; } } return tab;} put()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) { Node&lt;K,V&gt; f; int n, i, fh; K fk; V fv; if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) { if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value))) break; // no lock when adding to empty bin } else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else if (onlyIfAbsent // check first node without acquiring lock &amp;&amp; fh == hash &amp;&amp; ((fk = f.key) == key || (fk != null &amp;&amp; key.equals(fk))) &amp;&amp; (fv = f.val) != null) return fv; else { V oldVal = null; synchronized (f) { if (tabAt(tab, i) == f) { if (fh &gt;= 0) { binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) { K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) { pred.next = new Node&lt;K,V&gt;(hash, key, value); break; } } } else if (f instanceof TreeBin) { Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } else if (f instanceof ReservationNode) throw new IllegalStateException(&quot;Recursive update&quot;); } } if (binCount != 0) { if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } addCount(1L, binCount); return null;} 根据 key 计算出 hashcode，key和value均不能为null 。 判断是否需要进行初始化 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。 如果当前位置的 hashcode == MOVED == -1,则帮助扩容。 如果都不满足，则利用 synchronized 锁住这个桶,找到对应key替换值，或者插入到末尾 如果数量大于 TREEIFY_THRESHOLD 则要执行树化方法，在 treeifyBin 中会首先判断当前数组长度≥64时才会将链表转换为红黑树，与链表不同的是这个时候哈希桶里面存放的是TreeBin类，该类中有各种红黑树的方法 get()12345678910111213141516171819public V get(Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) { if ((eh = e.hash) == h) { if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; } else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) { if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; } } return null;} 根据 hash 值计算位置。 查找到指定位置，如果头节点就是要找的，直接返回它的 value. 如果头节点 hash 值小于 0 ，说明正在扩容或者是红黑树，查找之。 123static final int MOVED = -1; // hash for forwarding nodesstatic final int TREEBIN = -2; // hash for roots of treesstatic final int RESERVED = -3; // hash for transient reservations 如果是链表，遍历查找之。 addCount()1234567891011121314151617181920212223242526272829303132333435private final void addCount(long x, int check) { CounterCell[] cs; long b, s; if ((cs = counterCells) != null || !U.compareAndSetLong(this, BASECOUNT, b = baseCount, s = b + x)) { CounterCell c; long v; int m; boolean uncontended = true; if (cs == null || (m = cs.length - 1) &lt; 0 || (c = cs[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSetLong(c, CELLVALUE, v = c.value, v + x))) { fullAddCount(x, uncontended); return; } if (check &lt;= 1) return; s = sumCount(); } if (check &gt;= 0) { Node&lt;K,V&gt;[] tab, nt; int n, sc; while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) { int rs = resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT; if (sc &lt; 0) { if (sc == rs + MAX_RESIZERS || sc == rs + 1 || (nt = nextTable) == null || transferIndex &lt;= 0) break; if (U.compareAndSetInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); } else if (U.compareAndSetInt(this, SIZECTL, sc, rs + 2)) transfer(tab, null); s = sumCount(); } }} 使用了countercell数组的方法来计数，单个成员变量进行修改的时候冲突较大，所以采用分片的方法进行计数，方法类似于LongAdder计数 如果countercells数组为空，那么直接cas设置baseCount变量，失败了才进入if里面，初始化counterCells，使用fullCount初始化和重新计数counterCells，使用sumCount方法遍历counterCells 获取最后容量 如果check大于0，如果检查添加的元素量是否需要进行扩容。如果当前需要扩容，先判断是否有其他线程正在扩容有就更新sizeCTL+1（线程数+1），如果没有就更新sizeCTl rs+2（如果没有因为-1为初始化）重新计数，并且也要小于最大扩容线程数 Transfer()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) { int n = tab.length, stride; if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range if (nextTab == null) { // initiating try { @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; } catch (Throwable ex) { // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; } nextTable = nextTab; transferIndex = n; } int nextn = nextTab.length; ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab for (int i = 0, bound = 0;;) { Node&lt;K,V&gt; f; int fh; while (advance) { int nextIndex, nextBound; if (--i &gt;= bound || finishing) advance = false; else if ((nextIndex = transferIndex) &lt;= 0) { i = -1; advance = false; } else if (U.compareAndSetInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) { bound = nextBound; i = nextIndex - 1; advance = false; } } if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) { int sc; if (finishing) { nextTable = null; table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; } if (U.compareAndSetInt(this, SIZECTL, sc = sizeCtl, sc - 1)) { if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit } } else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); else if ((fh = f.hash) == MOVED) advance = true; // already processed else { synchronized (f) { if (tabAt(tab, i) == f) { Node&lt;K,V&gt; ln, hn; if (fh &gt;= 0) { int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) { int b = p.hash &amp; n; if (b != runBit) { runBit = b; lastRun = p; } } if (runBit == 0) { ln = lastRun; hn = null; } else { hn = lastRun; ln = null; } for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) { int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); } setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; } else if (f instanceof TreeBin) { TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) { int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) { if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; } else { if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; } } ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; } else if (f instanceof ReservationNode) throw new IllegalStateException(&quot;Recursive update&quot;); } } } }} 首先先划分每个线程的步长 为(n &gt;&gt;&gt; 3) / NCPU，如果只有一个cpu那么步长为整个表，同时还会在校验一次步长，小于16则设置为16 如果nextTab为空则，对数组进行扩容，申请原有数量两倍的数组，如果oom了则sizeCtl设为int最大值 然后就开始划分数组，如果node数组位置为空则直接设置fwd节点表示已经完成，moved标志表示该位置已经完成迁移无需操作，否则才会进入到链表和红黑树的迁移过程，类似于HashMap就不在赘述，最后一步同样也会设置fwd节点表示已经完成 完成特定步长后，sizeCtl-1设置结束标志退出，当最后一个线程完成后，他还会对全部数组进行个遍历确认是否有遗漏。","link":"/2023/03/30/JavaCollection/"},{"title":"java 并发","text":"参考链接：https://javaguide.cn/java/concurrent/java-concurrent-questions-02.html 参考书籍：深入理解java虚拟机第三版 Java 对象头 Mark Word 指向类的指针 数组长度（只有数组对象才有） 32位大小均为4个字节 java对象采取8字节对齐 高端面试必备：一个Java对象占用多大内存 - rickiyang - 博客园 (cnblogs.com) synchronized主要解决的是多个线程之间访问资源的同步性，可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。 历程在 Java 早期版本中，synchronized 属于 重量级锁，效率低下。这是因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高。 在 Java 6 之后， synchronized 引入了大量的优化如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。 使用方法synchronized 关键字加到 static 静态方法和 synchronized(class) 代码块上都是是给 Class 类上锁； synchronized 关键字加到实例方法上是给对象实例上锁； 尽量不要使用 synchronized(String a) 因为 JVM 中，字符串常量池具有缓存功能。 synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 synchronized 修饰的方法是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。如果是实例方法，JVM 会尝试获取实例对象的锁。如果是静态方法，JVM 会尝试获取当前 class 的锁。 锁分类级别从低到高依次是： 无锁状态 偏向锁状态 轻量级锁状态 重量级锁状态 锁可以升级，但不能降级。即：无锁 -&gt; 偏向锁 -&gt; 轻量级锁 -&gt; 重量级锁是单向的。 锁的升级参考 深入理解java虚拟机琐优化部分 自旋锁与自适应自旋在JDK 6中对自旋锁的优化，引入了自适应的自旋。自适应意味着自旋的时间不再是固定的了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定的。 如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而允许自旋等待持续相对更长的时间，比如持续100次忙循环。另一方面，如果对于某个锁，自旋很少成功获得过锁，那在以后要获取这个锁时将有可能直接省略掉自旋过程，以避免浪费处理器资源。 锁消除逃逸分析（Escape Analysis）简单来讲就是，Java Hotspot 虚拟机可以分析新创建对象的使用范围，并决定是否在 Java 堆上分配内存的一项技术。 当编译器确定一个对象没有发生逃逸时，它便会移除该对象的同步锁。 函数里多个同步方法，且所有引用没法逃逸出函数的使用范围，就可以去除同步方法。 额外标量替换 首先要明白标量和聚合量，基础类型和对象的引用可以理解为标量，它们不能被进一步分解。而能被进一步分解的量就是聚合量，比如：对象。 对象是聚合量，它又可以被进一步分解成标量，将其成员变量分解为分散的变量，这就叫做标量替换。 这样，如果一个对象没有发生逃逸，那压根就不用创建它，只会在栈或者寄存器上创建它用到的成员标量，节省了内存空间，也提升了应用程序性能。 标量替换在 JDK1.8 中也是默认开启的，但是同样也要建立在已开启逃逸分析的基础之上。 栈内存分配 栈内存分配很好理解，在上文中提过，就是将原本分配在堆内存上的对象转而分配在栈内存上，这样就可以减少堆内存的占用，从而减少 GC 的频次。 锁粗化如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部 轻量级锁加锁过程，会先在栈帧开辟一个锁记录的空间，记录原来markword中的值， 虚拟机将使用CAS操作尝试把对象的Mark Word更新为指向Lock Record的指针 解锁过程也同样是通过CAS操作来进行的，如果对象的Mark Word仍然指向线程的锁记录，那就用CAS操作把对象当前的Mark Word和线程中复制的Displaced Mark Word替换回来。假如能够成功替换，那整个同步过程就顺利完成了；如果替换失败，则说明有其他线程尝试过获取该锁，就要在释放锁的同时，唤醒被挂起的线程。 偏向锁Java6及以上版本对synchronized的优化 - 蜗牛大师 - 博客园 (cnblogs.com) 当锁对象第一次被线程获取的时候，虚拟机将会把对象头中的标志位设置为“01”、把偏向模式设置为“1”，表示进入偏向模式。同时使用CAS操作把获取到这个锁的线程的ID记录在对象的Mark Word之中。如果CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作（例如加锁、解锁及对Mark Word的更新操作等）。 一旦出现另外一个线程去尝试获取这个锁的情况，偏向模式就马上宣告结束。根据锁对象目前是否处于被锁定的状态决定是否撤销偏向（偏向模式设置为“0”），撤销后标志位恢复到未锁定（标志位为“01”）或轻量级锁定（标志位为“00”）的状态，后续的同步操作就按照上面介绍的轻量级锁那样去执行。偏向锁、轻量级锁的状态转化及对象Mark Word的关系如图所示。 当一个对象已经计算过一致性哈希码后，它就再也无法进入偏向锁状态了；而当一个对象当前正处于偏向锁状态，又收到需要计算其一致性哈希码请求[1]时，它的偏向状态会被立即撤销，并且锁会膨胀为重量级锁。(这里说的计算请求应来自于对Object::hashCode()或者System::identityHashCode(Object)方法的调用，如果重写了对象的hashCode()方法，计算哈希码时并不会产生这里所说的请求) Java内存模型 这里所讲的主内存、工作内存与第2章所讲的Java内存区域中的Java堆、栈、方法区等并不是同一个层次的对内存的划分，这两者基本上是没有任何关系的。如果两者一定要勉强对应起来，那么从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分[4]，而工作内存则对应于虚拟机栈中的部分区域。 UnsafeUnsafe 是位于 sun.misc 包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升 Java 运行效率、增强 Java 语言底层资源操作能力方面起到了很大的作用 主要功能分类 内存操作 内存屏障 123456//内存屏障，禁止load操作重排序。屏障前的load操作不能被重排序到屏障后，屏障后的load操作不能被重排序到屏障前public native void loadFence();//内存屏障，禁止store操作重排序。屏障前的store操作不能被重排序到屏障后，屏障后的store操作不能被重排序到屏障前public native void storeFence();//内存屏障，禁止load、store操作重排序public native void fullFence(); 对象操作 数据操作 CAS 操作 线程调度 Class 操作 系统信息 著作权归所有 原文链接：https://javaguide.cn/java/basis/unsafe.html 为啥要使用堆外内存。通常因为： 在进程间可以共享，减少虚拟机间的复制 对垃圾回收停顿的改善：如果应用某些长期存活并大量存在的对象，经常会出发YGC或者FullGC，可以考虑把这些对象放到堆外。过大的堆会影响Java应用的性能。如果使用堆外内存的话，堆外内存是直接受操作系统管理( 而不是虚拟机 )。这样做的结果就是能保持一个较小的堆内内存，以减少垃圾收集对应用的影响。 在某些场景下可以提升程序I/O操纵的性能。少去了将数据从堆内内存拷贝到堆外内存的步骤。 进程和线程Java 线程状态变迁图 线程初始状态：NEW 线程运行状态：RUNNABLE 线程阻塞状态：BLOCKED 线程等待状态：WAITING 超时等待状态：TIMED_WAITING 线程终止状态：TERMINATED volatile 关键字每次都要强制从主存中重新读取，如同直接在主内存中读写访问 123456789101112131415161718192021public class Singleton { private volatile static Singleton uniqueInstance; private Singleton() { } public static Singleton getUniqueInstance() { //先判断对象是否已经实例过，没有实例化过才进入加锁代码 if (uniqueInstance == null) { //类对象加锁 synchronized (Singleton.class) { if (uniqueInstance == null) { uniqueInstance = new Singleton(); } } } return uniqueInstance; }} uniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance = new Singleton(); 这段代码其实是分为三步执行： 为 uniqueInstance 分配内存空间 初始化 uniqueInstance 将 uniqueInstance 指向分配的内存地址 但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1-&gt;3-&gt;2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。 具体实现·lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。 ·unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 ·read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。 ·load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。 ·use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。 ·assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 ·store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。 ·write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中 后面最新的JSR-133文档中，已经放弃了采用这8种操作去定义Java内存模型的访问协议，缩减为4种read、write、lock和unlock 如果要把一个变量从主内存拷贝到工作内存，那就要按顺序执行read和load操作，如果要把变量从工作内存同步回主内存，就要按顺序执行store和write操作。注意，Java内存模型只要求上述两个操作必须按顺序执行，但不要求是连续执行，中间可以插入其他操作。 volatile 作用是在 use之前必须是load、load之前必须use 保证了每次使用都是最新值，assign和store也一样，保证了每次赋值都会写回到主内存 ReentrantLockReentrantLock 实现了 Lock 接口，是一个可重入且独占式的锁，和 synchronized 关键字类似。不过，ReentrantLock 更灵活、更强大，增加了轮询、超时、中断、公平锁和非公平锁等高级功能。","link":"/2023/04/18/javaConcurrent/"},{"title":"计算机网络","text":"https://xiaolincoding.com/network/3_tcp/tcp_interview.html TCP三次握手 三次握手才可以阻止重复历史连接的初始化（主要原因）主要是因为在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费。 三次握手才可以同步双方的初始序列号，两次握手无法知道对方是否收到自己的初始序列号 三次握手才可以避免资源浪费，两次握手服务端每次接受到syn报文就会建立一个连接 四次挥手 TCP与UDP TCP UDP 是否面向连接 是 否 是否可靠 是 否 是否有状态 是 否 传输效率 较慢 较快 传输形式 字节流 数据报文段 首部开销 20 ～ 60 bytes 8 bytes 是否提供广播或多播服务 否 是 QUIC连接1-RTT模式 0-RTT模式 对比 保持连接id 多路复用 拥塞控制","link":"/2023/05/27/network/"}],"tags":[{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"HashMap","slug":"HashMap","link":"/tags/HashMap/"},{"name":"Blog","slug":"Blog","link":"/tags/Blog/"},{"name":"Greedy","slug":"Greedy","link":"/tags/Greedy/"},{"name":"MergeSort","slug":"MergeSort","link":"/tags/MergeSort/"},{"name":"DynamicProgramming","slug":"DynamicProgramming","link":"/tags/DynamicProgramming/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"java，concurrent","slug":"java，concurrent","link":"/tags/java%EF%BC%8Cconcurrent/"},{"name":"network","slug":"network","link":"/tags/network/"}],"categories":[{"name":"Algorithm","slug":"Algorithm","link":"/categories/Algorithm/"},{"name":"Blog","slug":"Blog","link":"/categories/Blog/"},{"name":"java","slug":"java","link":"/categories/java/"},{"name":"concurrent","slug":"concurrent","link":"/categories/concurrent/"},{"name":"network","slug":"network","link":"/categories/network/"}],"pages":[]}